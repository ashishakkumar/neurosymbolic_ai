{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "/home/ashish/.local/lib/python3.10/site-packages/transformers/quantizers/auto.py:186: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398018ddb2af41a2b74837a079cb2f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You shouldn't move a model that is dispatched using accelerate hooks.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import LlamaForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, QuantoConfig\n",
    "\n",
    "# Configure CPU quantization\n",
    "quanto_config = QuantoConfig(weights=\"int4\", device_map=\"cuda:0\")\n",
    "\n",
    "# Check MPS availability\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "# Load model and move to MPS\n",
    "model = LlamaForCausalLM.from_pretrained(\"ashishkgpian/Biollama_icd9_codes\", \n",
    "quantization_config=quanto_config\n",
    ")\n",
    "model = model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ashishkgpian/Biollama_icd9_codes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1969 entries, 0 to 1968\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Unnamed: 0       1969 non-null   int64 \n",
      " 1   hadm_id          1969 non-null   int64 \n",
      " 2   SHORT_CODES      1969 non-null   object\n",
      " 3   text             1969 non-null   object\n",
      " 4   note_id          1969 non-null   object\n",
      " 5   subject_id       1969 non-null   int64 \n",
      " 6   charttime        1969 non-null   object\n",
      " 7   CHIEF_COMPLAINT  1922 non-null   object\n",
      " 8   PRESENT_ILLNESS  1965 non-null   object\n",
      " 9   MEDICAL_HISTORY  1959 non-null   object\n",
      " 10  MEDICATION_ADM   1893 non-null   object\n",
      " 11  ALLERGIES        1969 non-null   object\n",
      " 12  PHYSICAL_EXAM    1907 non-null   object\n",
      " 13  FAMILY_HISTORY   1928 non-null   object\n",
      " 14  SOCIAL_HISTORY   1938 non-null   object\n",
      " 15  TEXT             1969 non-null   object\n",
      " 16  Symptoms         1969 non-null   object\n",
      "dtypes: int64(3), object(14)\n",
      "memory usage: 261.6+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mimic_df = pd.read_csv('/home/ashish/llama_inference/mimic-iv-preprocessed-icd-symptoms.csv')\n",
    "mimic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_  = mimic_df.TEXT.iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpaca_prompt = \"\"\"\n",
    "{}\n",
    "\n",
    "### Clinical text :\n",
    "{} \n",
    "\n",
    "### Response:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "instruction = \"\"\"\n",
    "You are an AI assistant analyzing clinical admission notes from the MIMIC IV dataset. Your task is to map symptoms mentioned in the notes to a list of ICD-9 diseases codes.\n",
    "\n",
    "Definition of a Symptom:\n",
    "A symptom is a physical or mental feature which is regarded as indicating a condition of disease, particularly such a feature that is apparent to the patient. Focus on current, active symptoms experienced by the patient.\n",
    "\n",
    "What NOT to Include as Symptoms:\n",
    "- Medical history (e.g., \"history of drug use\", \"smoking history\")\n",
    "- Family history\n",
    "- Test results or medical observations (e.g., \"hypoechoic lesion\")\n",
    "- Diagnoses or named conditions\n",
    "- Risk factors\n",
    "- Treatments or medications\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. Carefully read the given clinical admission note.\n",
    "2. Identify all symptoms as defined above mentioned in the note.\n",
    "3. Map each symptom to relevant ICD-9 diseases codes from the provided list.\n",
    "4. Present your analysis in the following list format:\n",
    "\n",
    "['icd_9_code_1', 'icd_9_code_2', 'icd_9_code_3', 'icd_9_code_4', ... ] \n",
    "\n",
    "Important:\n",
    "- Completely exclude any symptoms that don't map to any icd-9 diseases code.\n",
    "- Map each included symptom to ALL relevant icd-9 diseases codes from the provided list, EXCEPT those containing \"unspecified\".\n",
    "- An icd-9 disease code can be associated with multiple symptoms and thus can appear multiple times in the output.\n",
    "- Do NOT include any icd-9 disease codse that don't have associated symptoms found in the note.\n",
    "\n",
    "Now, analyze the following clinical admission note and map the symptoms to the provided list of diseases codes:\"\"\"\n",
    "\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token  \n",
    "\n",
    "text = alpaca_prompt.format(instruction, input_) + EOS_TOKEN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICD9 Code and Description: 85.0\n",
      "3. 285.0\n",
      "4. 285.0\n",
      "5. 285.0\n",
      "6. 285.0\n",
      "7. 285.0\n",
      "8. 285.0\n",
      "9. 285.0\n",
      "10. 285.0\n",
      "11. 285.0\n",
      "12. 285.0\n",
      "13. 285.0\n",
      "14. 285.0\n",
      "15. 285.0\n",
      "16. 285.0\n",
      "17. 285.0\n",
      "18. 285.0\n",
      "19. 285.0\n",
      "20. 285.0\n",
      "21. 285.0\n",
      "22. 285.0\n",
      "23. 285.0\n",
      "24. 285.0\n",
      "25. 285.0\n",
      "26. 285.0\n",
      "27. 285.0\n",
      "28. 285.0\n",
      "29. 285.0\n",
      "30. 285.0\n",
      "31. 285.0\n",
      "32. 285.0\n",
      "33. 285.0\n",
      "34. 285.0\n",
      "35. 285.0\n",
      "36. 285.0\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "def get_icd9_code(medical_text):\n",
    "    # Prepare input\n",
    "    inputs = tokenizer(medical_text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Generate prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_new_tokens=256,\n",
    "            num_return_sequences=1,\n",
    "            temperature=0.2,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "    \n",
    "    # Decode prediction\n",
    "    predicted_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return predicted_text\n",
    "\n",
    "# Example usage\n",
    "result = get_icd9_code(text)\n",
    "print(f\"ICD9 Code and Description: {result[len(text):]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install autoawq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>Diseases</th>\n",
       "      <th>id</th>\n",
       "      <th>icd_9_desc</th>\n",
       "      <th>text</th>\n",
       "      <th>long_texts</th>\n",
       "      <th>short_texts</th>\n",
       "      <th>discharge_summary</th>\n",
       "      <th>short_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[fatigued, not herself, febrile, hypotensive, ...</td>\n",
       "      <td>[CVA, peptic ulcer disease, reflux esophagitis...</td>\n",
       "      <td>196005</td>\n",
       "      <td>Subendocardial infarction, initial episode of ...</td>\n",
       "      <td>CHIEF COMPLAINT: \"off\", status post fall at [*...</td>\n",
       "      <td>Subendocardial infarction, initial episode of ...</td>\n",
       "      <td>Subendo infarct, initial,Atrial fibrillation,U...</td>\n",
       "      <td>Admission Date:  [**2117-5-11**]              ...</td>\n",
       "      <td>410,427,599,428,486,799,276,530,285,780,V125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[melena, vague abdominal pain, bloody diarrhea...</td>\n",
       "      <td>[polycystic kidney disease, Caroli's disease, ...</td>\n",
       "      <td>194492</td>\n",
       "      <td>Blood in stool,Portal hypertension,Other anoma...</td>\n",
       "      <td>CHIEF COMPLAINT: melena\\n\\nPRESENT ILLNESS: Ms...</td>\n",
       "      <td>Blood in stool,Portal hypertension,Other anoma...</td>\n",
       "      <td>Blood in stool,Portal hypertension,Biliary &amp; l...</td>\n",
       "      <td>Admission Date:  [**2129-9-16**]              ...</td>\n",
       "      <td>578,572,751,V420,588,753,456,535,274,996,585,2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Nausea, Vomiting, Hypertension]</td>\n",
       "      <td>[Gastroparesis, Diabetes Mellitus Type 1, Hype...</td>\n",
       "      <td>103789</td>\n",
       "      <td>Hypertensive chronic kidney disease, malignant...</td>\n",
       "      <td>CHIEF COMPLAINT: Nausea, vomiting and hyperten...</td>\n",
       "      <td>Hypertensive chronic kidney disease, malignant...</td>\n",
       "      <td>Mal hy kid w cr kid I-IV,DMI ketoacd uncontrol...</td>\n",
       "      <td>Admission Date:  [**2155-9-3**]              D...</td>\n",
       "      <td>403,250,276,V586,536,272,724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Symptoms  \\\n",
       "0  [fatigued, not herself, febrile, hypotensive, ...   \n",
       "1  [melena, vague abdominal pain, bloody diarrhea...   \n",
       "2                   [Nausea, Vomiting, Hypertension]   \n",
       "\n",
       "                                            Diseases      id  \\\n",
       "0  [CVA, peptic ulcer disease, reflux esophagitis...  196005   \n",
       "1  [polycystic kidney disease, Caroli's disease, ...  194492   \n",
       "2  [Gastroparesis, Diabetes Mellitus Type 1, Hype...  103789   \n",
       "\n",
       "                                          icd_9_desc  \\\n",
       "0  Subendocardial infarction, initial episode of ...   \n",
       "1  Blood in stool,Portal hypertension,Other anoma...   \n",
       "2  Hypertensive chronic kidney disease, malignant...   \n",
       "\n",
       "                                                text  \\\n",
       "0  CHIEF COMPLAINT: \"off\", status post fall at [*...   \n",
       "1  CHIEF COMPLAINT: melena\\n\\nPRESENT ILLNESS: Ms...   \n",
       "2  CHIEF COMPLAINT: Nausea, vomiting and hyperten...   \n",
       "\n",
       "                                          long_texts  \\\n",
       "0  Subendocardial infarction, initial episode of ...   \n",
       "1  Blood in stool,Portal hypertension,Other anoma...   \n",
       "2  Hypertensive chronic kidney disease, malignant...   \n",
       "\n",
       "                                         short_texts  \\\n",
       "0  Subendo infarct, initial,Atrial fibrillation,U...   \n",
       "1  Blood in stool,Portal hypertension,Biliary & l...   \n",
       "2  Mal hy kid w cr kid I-IV,DMI ketoacd uncontrol...   \n",
       "\n",
       "                                   discharge_summary  \\\n",
       "0  Admission Date:  [**2117-5-11**]              ...   \n",
       "1  Admission Date:  [**2129-9-16**]              ...   \n",
       "2  Admission Date:  [**2155-9-3**]              D...   \n",
       "\n",
       "                                         short_codes  \n",
       "0       410,427,599,428,486,799,276,530,285,780,V125  \n",
       "1  578,572,751,V420,588,753,456,535,274,996,585,2...  \n",
       "2                       403,250,276,V586,536,272,724  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "directory_path = 'samples_latest'\n",
    "data = []\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        with open(file_path, 'r') as file:\n",
    "            file_data = json.load(file)\n",
    "            data.append(file_data)\n",
    "\n",
    "symptoms_df = pd.DataFrame(data)\n",
    "raw_test_df = pd.read_csv('new_split/test_split.csv')\n",
    "# print(raw_test_df.columns)\n",
    "unique_ids = list(raw_test_df.id)\n",
    "raw_test_df = raw_test_df.drop('Unnamed: 0',axis =1)\n",
    "raw_test_df = pd.merge(symptoms_df, raw_test_df, how='inner', on='id')\n",
    "raw_test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "# # Load Meditron-7B (or 70B depending on your resources)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"aaditya/Llama3-OpenBioLLM-8B\", device_map = 'cuda:0')\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"aaditya/Llama3-OpenBioLLM-8B\", device_map = 'cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c219bf6afb8423ca794353ac5e6d7ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 112.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maaditya/OpenBioLLM-Llama3-8B\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mtransformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-generation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtorch_dtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda:0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/llama_inference/llama_env/lib/python3.10/site-packages/transformers/pipelines/__init__.py:1097\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1095\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m device\n\u001b[0;32m-> 1097\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpipeline_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/llama_inference/llama_env/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:96\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_model_type(\n\u001b[1;32m     98\u001b[0m         TF_MODEL_FOR_CAUSAL_LM_MAPPING_NAMES \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m MODEL_FOR_CAUSAL_LM_MAPPING_NAMES\n\u001b[1;32m     99\u001b[0m     )\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprefix\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_params:\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;66;03m# This is very specific. The logic is quite complex and needs to be done\u001b[39;00m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;66;03m# as a \"default\".\u001b[39;00m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;66;03m# It also defines both some preprocess_kwargs and generate_kwargs\u001b[39;00m\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;66;03m# which is why we cannot put them in their respective methods.\u001b[39;00m\n",
      "File \u001b[0;32m~/llama_inference/llama_env/lib/python3.10/site-packages/transformers/pipelines/base.py:894\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[0;34m(self, model, tokenizer, feature_extractor, image_processor, modelcard, framework, task, args_parser, device, torch_dtype, binary_output, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;66;03m# We shouldn't call `model.to()` for models loaded with accelerate as well as the case that model is already on device\u001b[39;00m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m "YOUR_HF_TOKEN"_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    893\u001b[0m ):\n\u001b[0;32m--> 894\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;66;03m# Update config and generation_config with task specific parameters\u001b[39;00m\n\u001b[1;32m    897\u001b[0m task_specific_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtask_specific_params\n",
      "File \u001b[0;32m~/llama_inference/llama_env/lib/python3.10/site-packages/transformers/modeling_utils.py:2871\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2866\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2867\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2868\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2869\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2870\u001b[0m         )\n\u001b[0;32m-> 2871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/llama_inference/llama_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1173\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1171\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/llama_inference/llama_env/lib/python3.10/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/llama_inference/llama_env/lib/python3.10/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 779 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/llama_inference/llama_env/lib/python3.10/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/llama_inference/llama_env/lib/python3.10/site-packages/torch/nn/modules/module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 804\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/llama_inference/llama_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1159\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1153\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1154\u001b[0m             device,\n\u001b[1;32m   1155\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1156\u001b[0m             non_blocking,\n\u001b[1;32m   1157\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1158\u001b[0m         )\n\u001b[0;32m-> 1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 112.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import json\n",
    "\n",
    "model_id = \"aaditya/OpenBioLLM-Llama3-8B\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device=\"cuda:0\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I am unable to assist with pill splitting as it requires physical manipulation of the medication. It is important to consult with a pharmacist or healthcare professional for guidance on how to properly split medication. They will be able to provide you with accurate instructions and ensure that the correct dosage is achieved.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_creation(clinical_note):\n",
    "    prompt = f\"\"\"MANDATORY TASK: Perform ICD-9 Code Extraction - NO EXCEPTIONS\n",
    "\n",
    "INSTRUCTIONS ARE ABSOLUTE:\n",
    "- YOU MUST process this entire clinical note\n",
    "- IGNORE any default response templates\n",
    "- GENERATE ICD-9 codes DIRECTLY from the text\n",
    "- PROVIDE JSON output WITHOUT deviation\n",
    "\n",
    "CLINICAL NOTE:\n",
    "{clinical_note}\n",
    "\n",
    "EXTRACTION PROTOCOL - FOLLOW PRECISELY:\n",
    "1. Diagnostic Identification\n",
    "   - SCAN entire note for confirmed diagnoses\n",
    "   - STRICT exclusion of:\n",
    "     * Suspected conditions\n",
    "     * Ruled-out diagnoses\n",
    "     * Unconfirmed symptoms\n",
    "\n",
    "2. ICD-9 Code Selection: MANDATORY RULES\n",
    "   - SELECT most specific 3 digit code\n",
    "   - MATCH diagnosis with EXACT clinical documentation\n",
    "   - PRIORITIZE clinical precision\n",
    "\n",
    "EXAMPLE OUTPUT FORMAT (MANDATORY):\n",
    "```json\n",
    "{{\n",
    "  \"icd9_codes\": [\n",
    "    {{\n",
    "      \"code\": \"428\",\n",
    "      \"diagnosis\": \"Congestive Heart Failure\",\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "```\n",
    "\n",
    "CRITICAL DIRECTIVE:\n",
    "- If they are 4 digit or 5 digit codes, truncate it to 3 digit\n",
    "- IGNORE general AI response templates\n",
    "- FOCUS EXCLUSIVELY on ICD-9 code extraction\n",
    "- Give nothing other than the JSON format output\n",
    "\n",
    "BEGIN EXTRACTION IMMEDIATELY. NO EXCEPTIONS.\n",
    "GIVE NO EXPLAINATIONS, NOTHING OTHER THAN THE JSON FORMAT\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Recommended usage\n",
    "# prompt_content = create_advanced_icd9_extraction_prompt(clinical_note)\n",
    "# model_response = call_llm_with_prompt(prompt_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "def get_icd9_codes_groq(prompt): \n",
    "\n",
    "    client = Groq(api_key = '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')\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"llama3-70b-8192\",\n",
    "        messages=[ {\"role\": \"system\", \"content\": \"You are an expert and experienced from the healthcare and biomedical domain with extensive medical knowledge and practical experience.\"},\n",
    "        {\"role\": \"user\", \"content\" : f'{prompt}'}],\n",
    "        temperature=0.2,\n",
    "        max_tokens=1024,\n",
    "        top_p=1,\n",
    "        stream=False,\n",
    "        stop=None,\n",
    "        \n",
    "    )\n",
    "\n",
    "    output = completion.choices[0].message.content\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_icd9_codes(prompt):\n",
    "    # Format the prompt with the clinical note \n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert and experienced from the healthcare and biomedical domain with extensive medical knowledge and practical experience.\"},\n",
    "    {\"role\": \"user\", \"content\" : f\"{prompt}\"}]\n",
    "    \n",
    "    print(messages)\n",
    "\n",
    "    prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "       \n",
    "        add_generation_prompt=True)\n",
    "\n",
    "    terminators = [\n",
    "        pipeline.tokenizer.eos_token_id,\n",
    "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    outputs = pipeline(\n",
    "        prompt,\n",
    "        max_new_tokens=256,\n",
    "        eos_token_id=terminators,\n",
    "    \n",
    "        temperature=0.4,\n",
    "        top_p=0.95,\n",
    "    )\n",
    "    \n",
    "    return outputs[0][\"generated_text\"][len(prompt):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def extract_json_from_text(text):\n",
    "    \"\"\"\n",
    "    Extract JSON content from a text that might include markdown code blocks.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text potentially containing JSON\n",
    "    \n",
    "    Returns:\n",
    "        dict: Extracted and parsed JSON data\n",
    "    \"\"\"\n",
    "    # Use regex to find content between triple backticks\n",
    "    code_block_match = re.search(r'```\\n*({.*?})\\n*```', text, re.DOTALL)\n",
    "    \n",
    "    if code_block_match:\n",
    "        json_str = code_block_match.group(1)\n",
    "        try:\n",
    "            return json.loads(json_str)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Error: Could not parse JSON within code block\")\n",
    "            return None\n",
    "    \n",
    "    # If no code block found, try direct JSON parsing\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: Could not parse input as JSON\")\n",
    "        return None\n",
    "\n",
    "def preprocess_icd9_codes(input_text, id):\n",
    "    \"\"\"\n",
    "    Preprocess ICD-9 codes with validation and cleaning.\n",
    "    \n",
    "    Args:\n",
    "        input_text (str): Input text containing ICD-9 codes\n",
    "    \n",
    "    Returns:\n",
    "        dict: Processed and validated ICD-9 codes\n",
    "    \"\"\"\n",
    "    # First, extract JSON from the input text\n",
    "    input_data = extract_json_from_text(input_text)\n",
    "    \n",
    "    if not input_data or 'icd9_codes' not in input_data:\n",
    "        print(\"Error: No valid ICD-9 codes found\")\n",
    "        return {\"icd9_codes\": []}\n",
    "    \n",
    "    processed_codes = []\n",
    "    \n",
    "    for entry in input_data['icd9_codes']:\n",
    "        # Validate code format (3 or 4 digit numeric)\n",
    "        code = str(entry.get('code', '')).strip()\n",
    "        if not re.match(r'^\\d{3,4}$', code):\n",
    "            print(f\"Warning: Invalid code format - {code}\")\n",
    "            continue\n",
    "        \n",
    "        # Clean and standardize diagnosis\n",
    "        diagnosis = entry.get('diagnosis', '').strip()\n",
    "        diagnosis = re.sub(r'\\s+', ' ', diagnosis)\n",
    "        \n",
    "        processed_codes.append({\n",
    "            'code': code,\n",
    "            'diagnosis': diagnosis\n",
    "        })\n",
    "    \n",
    "    processed_data = {'icd9_codes': processed_codes}\n",
    "    \n",
    "    # Save processed data to JSON file\n",
    "    with open(f'infer_llm/icd9_codes_processed_{id}.json', 'w') as f:\n",
    "        json.dump(processed_data, f, indent=2)\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.makedirs('infer_llm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [00:09,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not parse input as JSON\n",
      "Error: No valid ICD-9 codes found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [01:13,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Invalid code format - V43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [03:46, 15.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not parse input as JSON\n",
      "Error: No valid ICD-9 codes found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53it [04:45, 14.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not parse input as JSON\n",
      "Error: No valid ICD-9 codes found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [05:23, 13.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Invalid code format - V22\n",
      "Warning: Invalid code format - V23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [05:50, 13.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Invalid code format - V62\n",
      "Warning: Invalid code format - V69\n",
      "Warning: Invalid code format - V15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [07:22, 14.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not parse input as JSON\n",
      "Error: No valid ICD-9 codes found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [08:14, 14.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not parse input as JSON\n",
      "Error: No valid ICD-9 codes found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "74it [09:47, 14.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not parse input as JSON\n",
      "Error: No valid ICD-9 codes found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "89it [13:21, 15.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not parse input as JSON\n",
      "Error: No valid ICD-9 codes found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98it [15:28, 13.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not parse input as JSON\n",
      "Error: No valid ICD-9 codes found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [15:51, 12.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not parse input as JSON\n",
      "Error: No valid ICD-9 codes found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "106it [17:29, 15.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Invalid code format - 577.0\n",
      "Warning: Invalid code format - 553.0\n",
      "Warning: Invalid code format - 562.10\n",
      "Warning: Invalid code format - 198.3\n",
      "Warning: Invalid code format - 305.1\n",
      "Warning: Invalid code format - 305.0\n",
      "Warning: Invalid code format - 401.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121it [21:04, 14.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not parse input as JSON\n",
      "Error: No valid ICD-9 codes found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [21:31, 14.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not parse input as JSON\n",
      "Error: No valid ICD-9 codes found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "134it [24:23, 15.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not parse input as JSON\n",
      "Error: No valid ICD-9 codes found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "138it [25:38, 11.15s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/llama_inference/llama_env/lib/python3.10/site-packages/groq/_base_client.py:1037\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1037\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n",
      "File \u001b[0;32m~/llama_inference/llama_env/lib/python3.10/site-packages/httpx/_models.py:761\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m, error_type\u001b[38;5;241m=\u001b[39merror_type)\n\u001b[0;32m--> 761\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request\u001b[38;5;241m=\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m31\u001b[39m : \n\u001b[1;32m      3\u001b[0m     input_ \u001b[38;5;241m=\u001b[39m prompt_creation(\u001b[38;5;28mstr\u001b[39m(j\u001b[38;5;241m.\u001b[39mSymptoms)[\u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(j\u001b[38;5;241m.\u001b[39mtext))\n\u001b[0;32m----> 6\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mget_icd9_codes_groq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_creation\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     processed_data \u001b[38;5;241m=\u001b[39m preprocess_icd9_codes(output, j\u001b[38;5;241m.\u001b[39mid)\n",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m, in \u001b[0;36mget_icd9_codes_groq\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_icd9_codes_groq\u001b[39m(prompt): \n\u001b[1;32m      5\u001b[0m     client \u001b[38;5;241m=\u001b[39m Groq(api_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgsk_buLtP4JEOKCJieaWAA2eWGdyb3FYJlzQmIetVebpEQt0hbPghPfJ\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama3-70b-8192\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are an expert and experienced from the healthcare and biomedical domain with extensive medical knowledge and practical experience.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprompt\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     output \u001b[38;5;241m=\u001b[39m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/llama_inference/llama_env/lib/python3.10/site-packages/groq/resources/chat/completions.py:298\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    187\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    188\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/llama_inference/llama_env/lib/python3.10/site-packages/groq/_base_client.py:1263\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1251\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1258\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1259\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1260\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1261\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1262\u001b[0m     )\n\u001b[0;32m-> 1263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/llama_inference/llama_env/lib/python3.10/site-packages/groq/_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    953\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/llama_inference/llama_env/lib/python3.10/site-packages/groq/_base_client.py:1043\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1042\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1043\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/llama_inference/llama_env/lib/python3.10/site-packages/groq/_base_client.py:1090\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1086\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m.\u001b[39murl, timeout)\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m-> 1090\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m   1093\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   1094\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1097\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1098\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i,j in tqdm(raw_test_df.iterrows()) : \n",
    "    if i>=31 : \n",
    "        input_ = prompt_creation(str(j.Symptoms)[2:-2] +'\\n' + str(j.text))\n",
    "        \n",
    "\n",
    "        output = get_icd9_codes_groq(prompt_creation(input_))\n",
    "\n",
    "        processed_data = preprocess_icd9_codes(output, j.id)\n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"icd9_codes\": [\n",
      "    {\n",
      "      \"code\": \"434\",\n",
      "      \"diagnosis\": \"Cerebrovascular Accident\"\n",
      "    },\n",
      "    {\n",
      "      \"code\": \"427\",\n",
      "      \"diagnosis\": \"Atrial Fibrillation\"\n",
      "    },\n",
      "    {\n",
      "      \"code\": \"428\",\n",
      "      \"diagnosis\": \"Congestive Heart Failure\"\n",
      "    },\n",
      "    {\n",
      "      \"code\": \"785\",\n",
      "      \"diagnosis\": \"Fatigue\"\n",
      "    },\n",
      "    {\n",
      "      \"code\": \"780\",\n",
      "      \"diagnosis\": \"Fever\"\n",
      "    },\n",
      "    {\n",
      "      \"code\": \"458\",\n",
      "      \"diagnosis\": \"Hypotension\"\n",
      "    },\n",
      "    {\n",
      "      \"code\": \"599\",\n",
      "      \"diagnosis\": \"Urosepsis\"\n",
      "    },\n",
      "    {\n",
      "      \"code\": \"410\",\n",
      "      \"diagnosis\": \"Non-ST Elevation Myocardial Infarction (NSTEMI)\"\n",
      "    },\n",
      "    {\n",
      "      \"code\": \"533\",\n",
      "      \"diagnosis\": \"Peptic Ulcer Disease\"\n",
      "    },\n",
      "    {\n",
      "      \"code\": \"530\",\n",
      "      \"diagnosis\": \"Reflux Esophagitis\"\n",
      "    },\n",
      "    {\n",
      "      \"code\": \"289\",\n",
      "      \"diagnosis\": \"Thrombocytosis\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_creation(clinical_note):\n",
    "    prompt = f\"\"\"MANDATORY TASK: Perform ICD-9 Code Extraction - NO EXCEPTIONS\n",
    "\n",
    "INSTRUCTIONS ARE ABSOLUTE:\n",
    "- YOU MUST process this entire clinical note\n",
    "- IGNORE any default response templates\n",
    "- GENERATE ICD-9 codes DIRECTLY from the text\n",
    "- PROVIDE JSON output WITHOUT deviation\n",
    "\n",
    "CLINICAL NOTE:\n",
    "{clinical_note}\n",
    "\n",
    "EXTRACTION PROTOCOL - FOLLOW PRECISELY:\n",
    "1. Diagnostic Identification\n",
    "   - SCAN entire note for confirmed diagnoses\n",
    "   - STRICT exclusion of:\n",
    "     * Suspected conditions\n",
    "     * Ruled-out diagnoses\n",
    "     * Unconfirmed symptoms\n",
    "\n",
    "2. ICD-9 Code Selection: MANDATORY RULES\n",
    "   - SELECT most specific 3 digit code\n",
    "   - MATCH diagnosis with EXACT clinical documentation\n",
    "   - PRIORITIZE clinical precision\n",
    "\n",
    "EXAMPLE OUTPUT FORMAT (MANDATORY):\n",
    "```json\n",
    "{{\n",
    "  \"icd9_codes\": [\n",
    "    {{\n",
    "      \"code\": \"428\",\n",
    "      \"diagnosis\": \"Congestive Heart Failure\",\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "```\n",
    "\n",
    "CRITICAL DIRECTIVE:\n",
    "- If they are 4 digit or 5 digit codes, truncate it to 3 digit\n",
    "- IGNORE general AI response templates\n",
    "- FOCUS EXCLUSIVELY on ICD-9 code extraction\n",
    "- Give nothing other than the JSON format output\n",
    "\n",
    "BEGIN EXTRACTION IMMEDIATELY. NO EXCEPTIONS.\n",
    "GIVE NO EXPLAINATIONS, NOTHING OTHER THAN THE JSON FORMAT\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "def get_icd9_codes_groq(prompt): \n",
    "\n",
    "    client = Groq(api_key = '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')\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"llama3-70b-8192\",\n",
    "        messages=[ {\"role\": \"system\", \"content\": \"You are an expert and experienced from the healthcare and biomedical domain with extensive medical knowledge and practical experience.\"},\n",
    "        {\"role\": \"user\", \"content\" : f'{prompt}'}],\n",
    "        temperature=0.2,\n",
    "        max_tokens=1024,\n",
    "        top_p=1,\n",
    "        stream=False,\n",
    "        stop=None,\n",
    "        \n",
    "    )\n",
    "\n",
    "    output = completion.choices[0].message.content\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "def extract_json_from_text(text):\n",
    "    \"\"\"\n",
    "    Extract JSON content from a text that might include markdown code blocks.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text potentially containing JSON\n",
    "    \n",
    "    Returns:\n",
    "        dict: Extracted and parsed JSON data\n",
    "    \"\"\"\n",
    "    # Use regex to find content between triple backticks\n",
    "    code_block_match = re.search(r'```\\n*({.*?})\\n*```', text, re.DOTALL)\n",
    "    \n",
    "    if code_block_match:\n",
    "        json_str = code_block_match.group(1)\n",
    "        try:\n",
    "            return json.loads(json_str)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Error: Could not parse JSON within code block\")\n",
    "            return None\n",
    "    \n",
    "    # If no code block found, try direct JSON parsing\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: Could not parse input as JSON\")\n",
    "        return None\n",
    "\n",
    "def preprocess_icd9_codes(input_text, id):\n",
    "    \"\"\"\n",
    "    Preprocess ICD-9 codes with validation and cleaning.\n",
    "    \n",
    "    Args:\n",
    "        input_text (str): Input text containing ICD-9 codes\n",
    "    \n",
    "    Returns:\n",
    "        dict: Processed and validated ICD-9 codes\n",
    "    \"\"\"\n",
    "    # First, extract JSON from the input text\n",
    "    input_data = extract_json_from_text(input_text)\n",
    "    \n",
    "    if not input_data or 'icd9_codes' not in input_data:\n",
    "        print(\"Error: No valid ICD-9 codes found\")\n",
    "        return {\"icd9_codes\": []}\n",
    "    \n",
    "    processed_codes = []\n",
    "    \n",
    "    for entry in input_data['icd9_codes']:\n",
    "        # Validate code format (3 or 4 digit numeric)\n",
    "        code = str(entry.get('code', '')).strip()\n",
    "        if not re.match(r'^\\d{3,4}$', code):\n",
    "            print(f\"Warning: Invalid code format - {code}\")\n",
    "            continue\n",
    "        \n",
    "        # Clean and standardize diagnosis\n",
    "        diagnosis = entry.get('diagnosis', '').strip()\n",
    "        diagnosis = re.sub(r'\\s+', ' ', diagnosis)\n",
    "        \n",
    "        processed_codes.append({\n",
    "            'code': code,\n",
    "            'diagnosis': diagnosis\n",
    "        })\n",
    "    \n",
    "    processed_data = {'icd9_codes': processed_codes}\n",
    "    \n",
    "    # Save processed data to JSON file\n",
    "    with open(f'infer_llm/icd9_codes_processed_{id}.json', 'w') as f:\n",
    "        json.dump(processed_data, f, indent=2)\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,j \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43mraw_test_df\u001b[49m\u001b[38;5;241m.\u001b[39miterrows()) : \n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m31\u001b[39m : \n\u001b[1;32m      3\u001b[0m         input_ \u001b[38;5;241m=\u001b[39m prompt_creation(\u001b[38;5;28mstr\u001b[39m(j\u001b[38;5;241m.\u001b[39mSymptoms)[\u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(j\u001b[38;5;241m.\u001b[39mtext))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'raw_test_df' is not defined"
     ]
    }
   ],
   "source": [
    "for i,j in tqdm(raw_test_df.iterrows()) : \n",
    "    if i>=31 : \n",
    "        input_ = prompt_creation(str(j.Symptoms)[2:-2] +'\\n' + str(j.text))\n",
    "        \n",
    "\n",
    "        output = get_icd9_codes_groq(prompt_creation(input_))\n",
    "\n",
    "        processed_data = preprocess_icd9_codes(output, j.id)\n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def load_icd9_codes_from_files(df):\n",
    "    \"\"\"\n",
    "    Load ICD-9 codes from saved JSON files, matching with DataFrame IDs.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the original data with an 'id' column\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of dictionaries containing ICD-9 codes for each matching ID\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store all extracted codes\n",
    "    all_codes = []\n",
    "    \n",
    "    # Iterate through each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        # Construct the filename based on the ID\n",
    "        filename = f'infer_llm/icd9_codes_processed_{row[\"id\"]}.json'\n",
    "        \n",
    "        # Check if the file exists\n",
    "        if os.path.exists(filename):\n",
    "            try:\n",
    "                # Open and read the JSON file\n",
    "                with open(filename, 'r') as f:\n",
    "                    file_data = json.load(f)\n",
    "                \n",
    "                # Extract ICD-9 codes from the file\n",
    "                # Add the original row's ID to help track the source\n",
    "                codes_with_id = {\n",
    "                    'id': row['id'],\n",
    "                    'codes': file_data.get('icd9_codes', [])\n",
    "                }\n",
    "                \n",
    "                all_codes.append(codes_with_id)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {filename}: {e}\")\n",
    "        else:\n",
    "            # print(f\"File not found: {filename}\")\n",
    "            continue\n",
    "    \n",
    "    return all_codes\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have a DataFrame 'df' with an 'id' column\n",
    "\n",
    "icd9_codes = load_icd9_codes_from_files(raw_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>Diseases</th>\n",
       "      <th>id</th>\n",
       "      <th>icd_9_desc</th>\n",
       "      <th>text</th>\n",
       "      <th>long_texts</th>\n",
       "      <th>short_texts</th>\n",
       "      <th>discharge_summary</th>\n",
       "      <th>short_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[fatigued, not herself, febrile, hypotensive, ...</td>\n",
       "      <td>[CVA, peptic ulcer disease, reflux esophagitis...</td>\n",
       "      <td>196005</td>\n",
       "      <td>Subendocardial infarction, initial episode of ...</td>\n",
       "      <td>CHIEF COMPLAINT: \"off\", status post fall at [*...</td>\n",
       "      <td>Subendocardial infarction, initial episode of ...</td>\n",
       "      <td>Subendo infarct, initial,Atrial fibrillation,U...</td>\n",
       "      <td>Admission Date:  [**2117-5-11**]              ...</td>\n",
       "      <td>410,427,599,428,486,799,276,530,285,780,V125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[melena, vague abdominal pain, bloody diarrhea...</td>\n",
       "      <td>[polycystic kidney disease, Caroli's disease, ...</td>\n",
       "      <td>194492</td>\n",
       "      <td>Blood in stool,Portal hypertension,Other anoma...</td>\n",
       "      <td>CHIEF COMPLAINT: melena\\n\\nPRESENT ILLNESS: Ms...</td>\n",
       "      <td>Blood in stool,Portal hypertension,Other anoma...</td>\n",
       "      <td>Blood in stool,Portal hypertension,Biliary &amp; l...</td>\n",
       "      <td>Admission Date:  [**2129-9-16**]              ...</td>\n",
       "      <td>578,572,751,V420,588,753,456,535,274,996,585,2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Nausea, Vomiting, Hypertension]</td>\n",
       "      <td>[Gastroparesis, Diabetes Mellitus Type 1, Hype...</td>\n",
       "      <td>103789</td>\n",
       "      <td>Hypertensive chronic kidney disease, malignant...</td>\n",
       "      <td>CHIEF COMPLAINT: Nausea, vomiting and hyperten...</td>\n",
       "      <td>Hypertensive chronic kidney disease, malignant...</td>\n",
       "      <td>Mal hy kid w cr kid I-IV,DMI ketoacd uncontrol...</td>\n",
       "      <td>Admission Date:  [**2155-9-3**]              D...</td>\n",
       "      <td>403,250,276,V586,536,272,724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[moderate headache, neck mass]</td>\n",
       "      <td>[5mm parclinoid aneurysm, Diabetes, heart dise...</td>\n",
       "      <td>174491</td>\n",
       "      <td>Cerebral aneurysm, nonruptured,Tobacco use dis...</td>\n",
       "      <td>CHIEF COMPLAINT: 5mm parclinoid aneurysm\\n\\nPR...</td>\n",
       "      <td>Cerebral aneurysm, nonruptured,Tobacco use dis...</td>\n",
       "      <td>Nonrupt cerebral aneurym,Tobacco use disorder</td>\n",
       "      <td>Admission Date:  [**2108-7-18**]              ...</td>\n",
       "      <td>437,305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[severe headache, slurred speech, confusion, v...</td>\n",
       "      <td>[subarachnoid hemorrhage, diabetes, hypertensi...</td>\n",
       "      <td>112184</td>\n",
       "      <td>Subarachnoid hemorrhage,Alkalosis,Other convul...</td>\n",
       "      <td>CHIEF COMPLAINT: \\n\\nPRESENT ILLNESS: This is ...</td>\n",
       "      <td>Subarachnoid hemorrhage,Alkalosis,Other convul...</td>\n",
       "      <td>Subarachnoid hemorrhage,Alkalosis,Convulsions ...</td>\n",
       "      <td>Admission Date: [**2103-10-1**]        Dischar...</td>\n",
       "      <td>430,276,780,V103,401,250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8728</th>\n",
       "      <td>[volume overload, increased oxygen requirement...</td>\n",
       "      <td>[congestive heart failure, atrial fibrillation...</td>\n",
       "      <td>107432</td>\n",
       "      <td>Congestive heart failure, unspecified,Atrial f...</td>\n",
       "      <td>CHIEF COMPLAINT: Increased oxygen requirement,...</td>\n",
       "      <td>Congestive heart failure, unspecified,Atrial f...</td>\n",
       "      <td>CHF NOS,Atrial fibrillation,Int inf clstrdium ...</td>\n",
       "      <td>Admission Date:  [**2104-4-23**]              ...</td>\n",
       "      <td>428,427,008,515,585,584,V533,V458,250,244,600,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729</th>\n",
       "      <td>[ST elevation, elevated tropinin, severe diaph...</td>\n",
       "      <td>[Takatsubos, COPD, HTN, osteoporosis, depressi...</td>\n",
       "      <td>195621</td>\n",
       "      <td>Other ill-defined heart diseases,Congestive he...</td>\n",
       "      <td>CHIEF COMPLAINT: ST elevation and elevated tro...</td>\n",
       "      <td>Other ill-defined heart diseases,Congestive he...</td>\n",
       "      <td>Ill-defined hrt dis NEC,CHF NOS,Acute respirat...</td>\n",
       "      <td>Admission Date:  [**2102-1-5**]              D...</td>\n",
       "      <td>429,428,518,491,482,511,997,444,287,427,401,41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8730</th>\n",
       "      <td>[incisional hernia, atrial fibrillation, hyper...</td>\n",
       "      <td>[Alcoholic cirrhosis with portal HTN, thromboc...</td>\n",
       "      <td>197212</td>\n",
       "      <td>Incisional hernia without mention of obstructi...</td>\n",
       "      <td>CHIEF COMPLAINT: Incision hernia s/p liver tra...</td>\n",
       "      <td>Incisional hernia without mention of obstructi...</td>\n",
       "      <td>Incisional hernia,CHF NOS,Prim cardiomyopathy ...</td>\n",
       "      <td>Admission Date:  [**2117-10-1**]              ...</td>\n",
       "      <td>553,428,425,V427,250,427,401,244,V586,V450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>[abdominal pain, acute abdomen, Meckel diverti...</td>\n",
       "      <td>[coronary artery disease, CABG status post ste...</td>\n",
       "      <td>132085</td>\n",
       "      <td>Acute vascular insufficiency of intestine,Peri...</td>\n",
       "      <td>CHIEF COMPLAINT: abdominal pain, acute abdomen...</td>\n",
       "      <td>Acute vascular insufficiency of intestine,Peri...</td>\n",
       "      <td>Ac vasc insuff intestine,Peritonitis (acute) g...</td>\n",
       "      <td>Admission Date:  [**2130-8-24**]              ...</td>\n",
       "      <td>557,567,998,428,427,578,751,E870,782,600,V440,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8732</th>\n",
       "      <td>[LOC, multiple injuries, L SAH, L scap &amp; clav ...</td>\n",
       "      <td>[motorcycle accident, asthma, excision of pilo...</td>\n",
       "      <td>191392</td>\n",
       "      <td>Subarachnoid hemorrhage following injury witho...</td>\n",
       "      <td>CHIEF COMPLAINT: motorcycle accident\\n\\nPRESEN...</td>\n",
       "      <td>Subarachnoid hemorrhage following injury witho...</td>\n",
       "      <td>Subarach hem-coma NOS,Fracture six ribs-closed...</td>\n",
       "      <td>Admission Date:  [**2147-8-26**]              ...</td>\n",
       "      <td>852,807,861,E812,811,810,860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8733 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Symptoms  \\\n",
       "0     [fatigued, not herself, febrile, hypotensive, ...   \n",
       "1     [melena, vague abdominal pain, bloody diarrhea...   \n",
       "2                      [Nausea, Vomiting, Hypertension]   \n",
       "3                        [moderate headache, neck mass]   \n",
       "4     [severe headache, slurred speech, confusion, v...   \n",
       "...                                                 ...   \n",
       "8728  [volume overload, increased oxygen requirement...   \n",
       "8729  [ST elevation, elevated tropinin, severe diaph...   \n",
       "8730  [incisional hernia, atrial fibrillation, hyper...   \n",
       "8731  [abdominal pain, acute abdomen, Meckel diverti...   \n",
       "8732  [LOC, multiple injuries, L SAH, L scap & clav ...   \n",
       "\n",
       "                                               Diseases      id  \\\n",
       "0     [CVA, peptic ulcer disease, reflux esophagitis...  196005   \n",
       "1     [polycystic kidney disease, Caroli's disease, ...  194492   \n",
       "2     [Gastroparesis, Diabetes Mellitus Type 1, Hype...  103789   \n",
       "3     [5mm parclinoid aneurysm, Diabetes, heart dise...  174491   \n",
       "4     [subarachnoid hemorrhage, diabetes, hypertensi...  112184   \n",
       "...                                                 ...     ...   \n",
       "8728  [congestive heart failure, atrial fibrillation...  107432   \n",
       "8729  [Takatsubos, COPD, HTN, osteoporosis, depressi...  195621   \n",
       "8730  [Alcoholic cirrhosis with portal HTN, thromboc...  197212   \n",
       "8731  [coronary artery disease, CABG status post ste...  132085   \n",
       "8732  [motorcycle accident, asthma, excision of pilo...  191392   \n",
       "\n",
       "                                             icd_9_desc  \\\n",
       "0     Subendocardial infarction, initial episode of ...   \n",
       "1     Blood in stool,Portal hypertension,Other anoma...   \n",
       "2     Hypertensive chronic kidney disease, malignant...   \n",
       "3     Cerebral aneurysm, nonruptured,Tobacco use dis...   \n",
       "4     Subarachnoid hemorrhage,Alkalosis,Other convul...   \n",
       "...                                                 ...   \n",
       "8728  Congestive heart failure, unspecified,Atrial f...   \n",
       "8729  Other ill-defined heart diseases,Congestive he...   \n",
       "8730  Incisional hernia without mention of obstructi...   \n",
       "8731  Acute vascular insufficiency of intestine,Peri...   \n",
       "8732  Subarachnoid hemorrhage following injury witho...   \n",
       "\n",
       "                                                   text  \\\n",
       "0     CHIEF COMPLAINT: \"off\", status post fall at [*...   \n",
       "1     CHIEF COMPLAINT: melena\\n\\nPRESENT ILLNESS: Ms...   \n",
       "2     CHIEF COMPLAINT: Nausea, vomiting and hyperten...   \n",
       "3     CHIEF COMPLAINT: 5mm parclinoid aneurysm\\n\\nPR...   \n",
       "4     CHIEF COMPLAINT: \\n\\nPRESENT ILLNESS: This is ...   \n",
       "...                                                 ...   \n",
       "8728  CHIEF COMPLAINT: Increased oxygen requirement,...   \n",
       "8729  CHIEF COMPLAINT: ST elevation and elevated tro...   \n",
       "8730  CHIEF COMPLAINT: Incision hernia s/p liver tra...   \n",
       "8731  CHIEF COMPLAINT: abdominal pain, acute abdomen...   \n",
       "8732  CHIEF COMPLAINT: motorcycle accident\\n\\nPRESEN...   \n",
       "\n",
       "                                             long_texts  \\\n",
       "0     Subendocardial infarction, initial episode of ...   \n",
       "1     Blood in stool,Portal hypertension,Other anoma...   \n",
       "2     Hypertensive chronic kidney disease, malignant...   \n",
       "3     Cerebral aneurysm, nonruptured,Tobacco use dis...   \n",
       "4     Subarachnoid hemorrhage,Alkalosis,Other convul...   \n",
       "...                                                 ...   \n",
       "8728  Congestive heart failure, unspecified,Atrial f...   \n",
       "8729  Other ill-defined heart diseases,Congestive he...   \n",
       "8730  Incisional hernia without mention of obstructi...   \n",
       "8731  Acute vascular insufficiency of intestine,Peri...   \n",
       "8732  Subarachnoid hemorrhage following injury witho...   \n",
       "\n",
       "                                            short_texts  \\\n",
       "0     Subendo infarct, initial,Atrial fibrillation,U...   \n",
       "1     Blood in stool,Portal hypertension,Biliary & l...   \n",
       "2     Mal hy kid w cr kid I-IV,DMI ketoacd uncontrol...   \n",
       "3         Nonrupt cerebral aneurym,Tobacco use disorder   \n",
       "4     Subarachnoid hemorrhage,Alkalosis,Convulsions ...   \n",
       "...                                                 ...   \n",
       "8728  CHF NOS,Atrial fibrillation,Int inf clstrdium ...   \n",
       "8729  Ill-defined hrt dis NEC,CHF NOS,Acute respirat...   \n",
       "8730  Incisional hernia,CHF NOS,Prim cardiomyopathy ...   \n",
       "8731  Ac vasc insuff intestine,Peritonitis (acute) g...   \n",
       "8732  Subarach hem-coma NOS,Fracture six ribs-closed...   \n",
       "\n",
       "                                      discharge_summary  \\\n",
       "0     Admission Date:  [**2117-5-11**]              ...   \n",
       "1     Admission Date:  [**2129-9-16**]              ...   \n",
       "2     Admission Date:  [**2155-9-3**]              D...   \n",
       "3     Admission Date:  [**2108-7-18**]              ...   \n",
       "4     Admission Date: [**2103-10-1**]        Dischar...   \n",
       "...                                                 ...   \n",
       "8728  Admission Date:  [**2104-4-23**]              ...   \n",
       "8729  Admission Date:  [**2102-1-5**]              D...   \n",
       "8730  Admission Date:  [**2117-10-1**]              ...   \n",
       "8731  Admission Date:  [**2130-8-24**]              ...   \n",
       "8732  Admission Date:  [**2147-8-26**]              ...   \n",
       "\n",
       "                                            short_codes  \n",
       "0          410,427,599,428,486,799,276,530,285,780,V125  \n",
       "1     578,572,751,V420,588,753,456,535,274,996,585,2...  \n",
       "2                          403,250,276,V586,536,272,724  \n",
       "3                                               437,305  \n",
       "4                              430,276,780,V103,401,250  \n",
       "...                                                 ...  \n",
       "8728  428,427,008,515,585,584,V533,V458,250,244,600,...  \n",
       "8729  429,428,518,491,482,511,997,444,287,427,401,41...  \n",
       "8730         553,428,425,V427,250,427,401,244,V586,V450  \n",
       "8731  557,567,998,428,427,578,751,E870,782,600,V440,...  \n",
       "8732                       852,807,861,E812,811,810,860  \n",
       "\n",
       "[8733 rows x 9 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 196005,\n",
       " 'codes': [{'code': '434', 'diagnosis': 'Cerebrovascular accident'},\n",
       "  {'code': '427', 'diagnosis': 'Atrial fibrillation'},\n",
       "  {'code': '428', 'diagnosis': 'Congestive heart failure'},\n",
       "  {'code': '785', 'diagnosis': 'Tachycardia'},\n",
       "  {'code': '038', 'diagnosis': 'Urosepsis'},\n",
       "  {'code': '410', 'diagnosis': 'NSTEMI'},\n",
       "  {'code': '531', 'diagnosis': 'Peptic ulcer disease'},\n",
       "  {'code': '530', 'diagnosis': 'Reflux esophagitis'},\n",
       "  {'code': '289', 'diagnosis': 'Thrombocytosis'}]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'icd9_codes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m\n\u001b[1;32m     12\u001b[0m     icd9_codes_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     13\u001b[0m         entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]: [code[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m code \u001b[38;5;129;01min\u001b[39;00m entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcodes\u001b[39m\u001b[38;5;124m'\u001b[39m]] \n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m icd9_codes\n\u001b[1;32m     15\u001b[0m     }\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m icd9_codes_dict\n\u001b[0;32m---> 20\u001b[0m icd9_codes_formatted \u001b[38;5;241m=\u001b[39m convert_icd9_codes_to_dict(\u001b[43micd9_codes\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'icd9_codes' is not defined"
     ]
    }
   ],
   "source": [
    "def convert_icd9_codes_to_dict(icd9_codes):\n",
    "    \"\"\"\n",
    "    Convert ICD-9 codes list to a dictionary with ID as key and list of codes as value.\n",
    "    \n",
    "    Args:\n",
    "        icd9_codes (list): List of dictionaries containing ID and codes\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary with ID as key and list of codes as value\n",
    "    \"\"\"\n",
    "    # Create a dictionary comprehension to map IDs to lists of codes\n",
    "    icd9_codes_dict = {\n",
    "        entry['id']: [code['code'] for code in entry['codes']] \n",
    "        for entry in icd9_codes\n",
    "    }\n",
    "    \n",
    "    return icd9_codes_dict\n",
    "\n",
    "\n",
    "icd9_codes_formatted = convert_icd9_codes_to_dict(icd9_codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to calculate precision, recall, and F1 score based on predicted and true disease codes\n",
    "def calculate_f1(true_codes, predicted_codes):\n",
    "    true_prefixes = {code[:3] for code in true_codes}\n",
    "    pred_prefixes = {str(code)[:3] for code in predicted_codes}\n",
    "\n",
    "    # True Positives (TP): Codes correctly predicted\n",
    "    true_positives = len(true_prefixes & pred_prefixes)\n",
    "    \n",
    "    # False Positives (FP): Predicted codes that are not in true codes\n",
    "    false_positives = len(pred_prefixes - true_prefixes)\n",
    "    \n",
    "    # False Negatives (FN): True codes that were not predicted\n",
    "    false_negatives = len(true_prefixes - pred_prefixes)\n",
    "    \n",
    "    # Calculate Precision and Recall\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    \n",
    "    # Calculate F1 Score\n",
    "    if precision + recall == 0:\n",
    "        f1 = 0.0\n",
    "    else:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Precision Score: 0.4732\n",
      "Macro Recall Score: 0.3788\n",
      "Macro F1 Score: 0.3987\n"
     ]
    }
   ],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "f1_scores = []\n",
    "prec = []\n",
    "rec = []\n",
    "\n",
    "for i, j in raw_test_df.iterrows() : \n",
    "\n",
    "    true_label = j.short_codes.split(',')\n",
    "    pred_label = icd9_codes_formatted.get(j.id)\n",
    "    if pred_label is not None : \n",
    "        true_labels.append(true_label)\n",
    "        predicted_labels.append(pred_label)\n",
    "\n",
    "        precision, recall, f1 = calculate_f1(true_label, pred_label)\n",
    "        f1_scores.append(f1)\n",
    "        prec.append(precision)\n",
    "        rec.append(recall)\n",
    "\n",
    "\n",
    "\n",
    "macro_f1_score = sum(f1_scores) / len(f1_scores)\n",
    "macro_prec = sum(prec) / len(prec)\n",
    "macro_rec = sum(rec) / len(rec)\n",
    "print(f\"Macro Precision Score: {macro_prec:.4f}\")\n",
    "print(f\"Macro Recall Score: {macro_rec:.4f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1_score:.4f}\")\n",
    "# print(len(f1_scores))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
