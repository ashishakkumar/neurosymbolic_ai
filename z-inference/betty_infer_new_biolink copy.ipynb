{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- table : \n",
    "input the subject id (two three words ...) output : extracted symptoms_test (show the symptom line)\n",
    "\n",
    "symptoms extraction using llm (3.3)\n",
    "\n",
    "- we randomly chose the 100 instances and then validatied it from medical experts\n",
    "\n",
    "mimic preprocessing alag kro  (don't mention the split, wo alag se aayega) (maybe section 3.2)\n",
    "\n",
    "- properly cite kro ki kahan se extraction kiya hai (betty , family history)\n",
    "\n",
    "- deep learning methods (find out and report it there)\n",
    "\n",
    "- Make the method diagram\n",
    "\n",
    "dataset sections : we have taken the same section as betty (clearly mentions kro) : then mention ki 10% training se liya\n",
    "\n",
    "\n",
    "- Add prompt of LLM incontext\n",
    "\n",
    "- Use llm as a classsifer (confidence score, icd -9 codes) : iska sbse accha aan chahiye.\n",
    "\n",
    "- Model parameters : mention the bert parameters, the learning rate, the optimizers , etc (kitna hai biobert me) , and then also mention about the biobert threshold parameters as well \n",
    "\n",
    "- do the t-test on biobert and biobert + KG (On both the frameworks : knowing the number of outputs for each instance , and not knowing the number of outputs for each instance). Take the f-score of each method side by side and then clacualte the t-test\n",
    "\n",
    "Model Interpretability \n",
    "\n",
    "- Attention score from BERT : code dene pr RAG me kya code ko jyada attention de rha kya\n",
    "- Captum (IBM)\n",
    "\n",
    "Limitations on current approach and how to improve it\n",
    " -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install weaviate-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mistralai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers groq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mistralai.client import MistralClient\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from mistralai.client import MistralClient\n",
    "from mistralai import Mistral, UserMessage\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_creation(clinical_note):\n",
    "    prompt = f\"\"\"MANDATORY TASK: Perform ICD-9 Code Extraction - NO EXCEPTIONS\n",
    "\n",
    "INSTRUCTIONS ARE ABSOLUTE:\n",
    "- YOU MUST process this entire clinical note\n",
    "- IGNORE any default response templates\n",
    "- GENERATE ICD-9 codes DIRECTLY from the text\n",
    "- PROVIDE JSON output WITHOUT deviation\n",
    "- GO THROUGH THE most probable ICD-9 codes provided in the first line of the note\n",
    "\n",
    "CLINICAL NOTE:\n",
    "{clinical_note}\n",
    "\n",
    "EXTRACTION PROTOCOL - FOLLOW PRECISELY:\n",
    "1. Diagnostic Identification\n",
    "   - SCAN entire note for confirmed diagnoses\n",
    "   - STRICT exclusion of:\n",
    "     * Suspected conditions\n",
    "     * Ruled-out diagnoses\n",
    "     * Unconfirmed symptoms\n",
    "\n",
    "2. ICD-9 Code Selection: MANDATORY RULES\n",
    "   - SELECT most specific 3 digit code\n",
    "   - MATCH diagnosis with EXACT clinical documentation\n",
    "   - PRIORITIZE clinical precision\n",
    "   - Additionally select the ICD-9 codes from the first line of clinical note, if they are associated with this note\n",
    "\n",
    "EXAMPLE OUTPUT FORMAT (MANDATORY):\n",
    "```json\n",
    "{{\n",
    "  \"icd9_codes\": [\n",
    "    {{\n",
    "      \"code\": \"428\",\n",
    "      \"diagnosis\": \"Congestive Heart Failure\",\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "```\n",
    "\n",
    "CRITICAL DIRECTIVE:\n",
    "- If they are 4 digit or 5 digit codes, truncate it to 3 digit\n",
    "- IGNORE general AI response templates\n",
    "- FOCUS EXCLUSIVELY on ICD-9 code extraction\n",
    "- Give nothing other than the JSON format output\n",
    "\n",
    "BEGIN EXTRACTION IMMEDIATELY. NO EXCEPTIONS.\n",
    "GIVE NO EXPLAINATIONS, NOTHING OTHER THAN THE JSON FORMAT\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "def prompt_creation_rag(clinical_note, references):\n",
    "    prompt = f\"\"\"MANDATORY TASK: Perform ICD-9 Code Extraction - NO EXCEPTIONS\n",
    "\n",
    "INSTRUCTIONS ARE ABSOLUTE:\n",
    "- YOU MUST process this entire clinical note\n",
    "- IGNORE any default response templates\n",
    "- GENERATE ICD-9 codes DIRECTLY from the text\n",
    "- PROVIDE JSON output WITHOUT deviation\n",
    "- GO THROUGH THE most probable ICD-9 codes provided in the first line of the note\n",
    "- Go through the reference PUBMed Atricles provided in the # REFERENCE SECTION\n",
    "\n",
    "CLINICAL NOTE:\n",
    "{clinical_note}\n",
    "\n",
    "EXTRACTION PROTOCOL - FOLLOW PRECISELY:\n",
    "1. Diagnostic Identification\n",
    "   - SCAN entire note for confirmed diagnoses\n",
    "   - STRICT exclusion of:\n",
    "     * Suspected conditions\n",
    "     * Ruled-out diagnoses\n",
    "     * Unconfirmed symptoms\n",
    "\n",
    "2. ICD-9 Code Selection: MANDATORY RULES\n",
    "   - SELECT most specific 3 digit code\n",
    "   - MATCH diagnosis with EXACT clinical documentation\n",
    "   - PRIORITIZE clinical precision\n",
    "   - Additionally select the ICD-9 codes from the first line of clinical note, if they are associated with this note\n",
    "\n",
    "EXAMPLE OUTPUT FORMAT (MANDATORY):\n",
    "```json\n",
    "{{\n",
    "  \"icd9_codes\": [\n",
    "    {{\n",
    "      \"code\": \"428\",\n",
    "      \"diagnosis\": \"Congestive Heart Failure\",\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "```\n",
    "\n",
    "# REFERENCE\n",
    "{references}\n",
    "\n",
    "CRITICAL DIRECTIVE:\n",
    "- If they are 4 digit or 5 digit codes, truncate it to 3 digit\n",
    "- IGNORE general AI response templates\n",
    "- FOCUS EXCLUSIVELY on ICD-9 code extraction\n",
    "- Give nothing other than the JSON format output\n",
    "\n",
    "BEGIN EXTRACTION IMMEDIATELY. NO EXCEPTIONS.\n",
    "GIVE NO EXPLAINATIONS, NOTHING OTHER THAN THE JSON FORMAT\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "def get_icd9_codes_groq(prompt): \n",
    "\n",
    "    client = Groq(api_key = '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')\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"llama3-70b-8192\",\n",
    "        messages=[ {\"role\": \"system\", \"content\": \"You are an expert and experienced from the healthcare and biomedical domain with extensive medical knowledge and practical experience.\"},\n",
    "        {\"role\": \"user\", \"content\" : f'{prompt}'}],\n",
    "        temperature=0.2,\n",
    "        max_tokens=1024,\n",
    "        top_p=1,\n",
    "        stream=False,\n",
    "        stop=None,\n",
    "        \n",
    "    )\n",
    "\n",
    "    output = completion.choices[0].message.content\n",
    "    return output\n",
    "\n",
    "def get_icd9_codes_mistral(prompt) : \n",
    "\n",
    "    model= \"mistral-small-latest\" \n",
    "    MISTRAL_API_KEY =  \"WRhxY4qx7jsun5iYThrdS3Dk4dubsjnV\"\n",
    "\n",
    "    client = Mistral(\n",
    "        api_key=MISTRAL_API_KEY )\n",
    "\n",
    "\n",
    "\n",
    "    chat_response = client.chat.complete(\n",
    "        model=model,\n",
    "        max_tokens=1000,\n",
    "        temperature=0.1,\n",
    "        messages=[UserMessage(content=f\"{prompt}\",), ])\n",
    "    \n",
    "    output = chat_response.choices[0].message.content\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# import torch\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device)\n",
    "# # # Load the pre-trained CORe model\n",
    "# # tokenizer = AutoTokenizer.from_pretrained(\"ashishkgpian/betty_icd9_classifier_ehr_symptoms_text_icd9_150_epochs\")\n",
    "# # model = AutoModelForSequenceClassification.from_pretrained(\"ashishkgpian/betty_icd9_classifier_ehr_symptoms_text_icd9_150_epochs\")\n",
    "# # model.to(device)\n",
    "\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"ashishkgpian/biolink_large_disease_classification\" )\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"ashishkgpian/biolink_large_disease_classification\",revision ='710d527b88abc7310fc517c53d6f30515280f58f', ignore_mismatched_sizes=True)\n",
    "# model.to(device)\n",
    "\n",
    "# classes = str('403 486 582 585 425 276 710 724 458 287 285 275 583 558 327 228 338 789 790 V451 531 410 414 725 191 331 530 411 482 272 305 194 197 255 424 584 998 682 511 599 428 349 401 V100 V453 V586 041 251 E932 V300 V053 V290 571 070 250 570 572 286 518 038 280 263 995 303 244 112 881 903 955 E956 745 762 441 496 447 440 997 274 427 V104 V101 V120 V090 569 560 491 V458 433 436 493 996 416 V310 765 769 774 770 747 776 772 362 198 V103 746 766 V293 853 780 E888 730 357 430 293 443 V158 396 365 135 311 E935 721 214 437 242 600 189 304 711 800 E814 873 781 378 951 767 431 294 042 V141 V071 764 775 969 295 E950 266 779 355 553 965 E850 E853 426 804 E916 202 V502 398 707 348 787 564 V428 238 300 788 332 V107 V433 E879 861 423 E966 200 555 771 270 335 723 079 851 807 864 865 860 413 782 V108 507 512 752 162 783 778 333 785 136 799 E931 157 574 568 E878 722 719 V125 296 478 V170 805 596 E880 822 733 578 459 438 008 V098 185 967 225 V457 389 412 593 345 201 515 E933 278 492 715 415 V105 535 608 E870 V058 513 709 E821 V173 824 911 913 E812 576 203 281 580 V450 216 V340 579 693 351 088 714 E849 307 421 786 E942 959 E928 588 364 V642 V025 252 283 784 611 622 289 446 729 V498 V456 795 E854 V667 155 V130 882 852 957 E815 466 792 434 342 153 E934 481 910 456 453 867 273 532 806 V422 V541 556 394 444 924 E960 514 763 218 359 340 999 451 324 E939 537 737 455 E884 V427 591 592 577 557 575 356 368 552 500 750 253 292 E937 211 288 773 314 V652 432 379 435 E930 199 V641 494 966 758 E855 741 918 V436 078 562 820 801 839 E881 V584 731 E885 812 156 567 696 501 712 V707 215 754 753 508 876 720 V442 871 958 802 847 397 196 346 E968 510 404 360 376 370 V026 904 928 821 823 150 573 850 V497 E938 V533 V556 728 870 V874 V153 V644 V600 521 301 164 054 344 464 442 V150 282 V08 891 808 866 902 117 484 760 V048 691 519 528 320 369 685 V625 794 793 318 V441 761 936 E915 457 395 053 V113 V632 386 623 290 204 271 E819 811 813 884 E813 751 366 297 V440 473 E910 V420 057 536 152 970 485 235 372 E882 127 160 170 V880 595 909 V443 490 343 319 130 698 E823 246 854 868 872 982 151 V853 980 E980 291 517 268 487 E866 796 V452 036 354 648 701 V063 V038 227 614 533 736 942 E924 240 921 V454 977 759 768 923 E816 681 138 358 950 922 205 990 009 619 417 279 257 E860 755 991 E957 241 810 920 V461 V127 261 429 550 874 756 935 831 718 962 E858 803 480 674 277 880 879 377 529 047 083 835 462 336 E947 V160 420 317 454 E883 840 V550 960 586 933 597 350 E911 742 V614 298 V551 620 716 V462 V180 706 565 452 825 322 154 040 110 605 607 461 704 713 945 052 948 323 325 934 516 039 975 971 994 666 V111 907 E929 566 603 405 049 237 V161 V553 262 743 422 337 625 757 527 309 815 V163 402 869 E912 188 590 V852 V446 E852 886 E919 183 862 875 877 890 E944 E936 V444 598 V552 226 E818 617 E958 V123 748 968 V298 465 972 E826 905 E969 744 E829 V301 388 V146 V151 887 375 334 E848 E918 284 E876 260 987 E890 834 522 692 V588 310 863 E834 192 035 V174 171 738 220 477 212 172 V548 726 526 V099 777 749 E922 952 V320 901 542 449 V011 963 E822 524 V052 V539 144 445 321 380 604 383 587 137 845 695 V496 180 618 V102 540 525 916 174 V628 892 816 V171 520 708 176 791 V854 E906 V714 V554 V435 883 927 V434 007 581 V202 140 642 644 654 V270 V252 193 V838 V555 139 V195 V068 601 826 694 626 956 245 919 299 727 684 647 E941 V850 665 391 308 633 639 V230 V061 223 269 V183 046 534 361 673 643 986 005 034 382 239 232 V169 E901 908 634 836 616 E917 734 V698 133 E887 V445 V155 E949 142 E987 236 470 463 E940 229 448 702 182 E825 V851 814 V881 259 906 161 E891 830 E953 195 093 472 914 E988 930 543 686 900 075 705 939 381 V311 V168 018 004 917 483 656 641 217 V291 V164 E943 134 635 659 E920 506 E869 111 096 094 123 158 141 243 690 097 632 989 964 027 V596 373 V017 254 932 187 353 669 V504 602 843 912 374 983 E864 031 210 114 646 077 V018 670 615 V638 V135 938 V580 680 878 E965 471 652 663 658 V272 213 032 148 V643 V148 V062 E989 E927 131 233 V040 V066 125 V503 V581 V292 V192 700 703 209 V029 208 697 E871 184 015 146 V140 V154 992 249 149 V142 844 175 V542 363 V152 V106 V688 V265 012 885 E955 V530 385 V124 V741 390 474 627 817 230 E817 V198 E862 258 V463 735 V024 V640 976 E861 V765 V023 V626 E828 V188 341 V560 798 V448 893 495 084 523 V653 953 V549 V095 V182 621 475 V425 058 306 V165 551 E831 V136 V109 256 219 221 961 985 828 671 E820 897 V840 926 V421 048 594 896 082 E986 541 145 267 683 V097 732 265 011 E801 V185 664 V620 E840 V166 V468 629 115 V587 E908 120 V708 098 V469 V694 E824 E970 121 838 832 460 013 V239 944 V189 946 118 326 E945 645 352 159 E967 V618 147 V908 941 312 624 V186 V145 661 010 E865 091 E886 649 E905 E962 V612 E959 502 V438 V222 163 947 V162 E946 V716 315 367 V540 846 717 V561 V175 842 V138 V703 V583 841 672 062 488 347 339 E841 086 V400 E985 655 974 V289 V604 V074 V728 371 190 V126 090 143 943 V611 V331 085 V172 E835 668 740 V167 V558 E851 E811 V430 837 V072 V431 302 E923 V110 E900 V562 E963 E964 V118 V624 E800 988 833 023 V020 021 003 V660 E806 313 E954 V860 660 V449 231 V602 186 E863 E874 V721 V181 651 033 V654 E804 330 610 384 E838 E001 973 819 014 132 E899 925 207 V861 E002 E030 E000 894 E873 E999 E976 E003 V016 E805 045 V610 V078 V510 E029 848 E006 V403 122 V536 E013 E019 173 E913 677 E008 V568 V143 V091 V872 066 V601 116 V882 V065 538 V655 316 E007 E016 E921 V902 206 V254 099 V489 V870 E977 628 V250 E982 V486 539 V073 937 V812 030 V271 589 V672 V671 E926 E925 E857 V537 954 E827 657 V910 V789 V037 E975 V045 V848 393 V426 179 387 V903 E856 V901 915').split(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import HfApi, model_info\n",
    "\n",
    "# # Get all repository references\n",
    "# api = HfApi()\n",
    "# refs = api.list_repo_refs(\"ashishkgpian/biolink_large_disease_classification\")\n",
    "\n",
    "# refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashish/Documents/mappe/weaviate_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(classes)\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to Neo4j\n",
    "class Neo4jHandler:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "    \n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "    def query_kg(self, symptoms, true_length):\n",
    "        \"\"\"\n",
    "        Query the KG for diseases related to the given symptoms.\n",
    "        \"\"\"\n",
    "        query = \"\"\"\n",
    "        MATCH (s:Symptom)-[r:HAS_SYMPTOM]-(d:Disease)\n",
    "    WHERE s.name IN $symptoms OR any(synonym IN s.synonyms WHERE synonym IN $symptoms)\n",
    "    RETURN d.id AS disease, r.weight AS weight\n",
    "    ORDER BY weight DESC\n",
    "    LIMIT $true_length\n",
    "        \"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(query, symptoms=symptoms, true_length=true_length)\n",
    "            return [{\"disease\": record[\"disease\"], \"weight\": record[\"weight\"]} for record in result]\n",
    "\n",
    "neo4j_handler = Neo4jHandler(\"bolt://localhost:8687\", \"neo4j\", \"neo4j_pass5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions with RAG\n",
    "1. USING MIMIC : Pass the query expanded symptoms as well as the codes\n",
    "2. USING THE PUBMED KG : Pass the output codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MIMIC Approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  pip install py2neo dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from py2neo import Graph\n",
    "from mistralai.client import MistralClient\n",
    "# from mistralai.models.chat_completion import ChatMessage\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "uri = \"neo4j://localhost:8687\" \n",
    "auth = (\"neo4j\", \"neo4j_pass5\")\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=auth) \n",
    "driver.verify_connectivity()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For checking the matching symptoms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['upper extremity tenderness', 'extremity tenderness', 'extremity tremor', 'extremity swelling', 'bilateral otalgia', 'alexia with agraphia', 'cough with fever', 'fever with rash', 'pain with eye movement', 'primary headache associated with sexual activity', 'organ failure', 'renal problem', 'renal colic', 'acute retention', 'acute dyspnea', 'upper extremity tenderness', 'extremity tenderness', 'extremity tremor', 'extremity swelling', 'lower extremity paresthesias', 'diastolic rumble', 'chronic vomiting', 'chronic constipation', 'chronic vertigo', 'pain, chronic', 'gi symptoms']\n"
     ]
    }
   ],
   "source": [
    "def escape_special_chars(query):\n",
    "    return query.replace(\"'\", \"\\\\'\").replace(\"/\", \"\\\\/\")\n",
    "\n",
    "def search_symptoms(query_strings,limit = 5):\n",
    "    all_symptoms = []\n",
    "    for query_string in query_strings:\n",
    "        escaped_query = escape_special_chars(query_string)  # Escape the query string\n",
    "        with driver.session() as session:\n",
    "            result = session.run(\n",
    "                f\"CALL db.index.fulltext.queryNodes('symptomIndex', '{escaped_query}') \"\n",
    "                \"YIELD node, score \"\n",
    "                \"RETURN node.name AS symptom, score \"\n",
    "                \"ORDER BY score DESC \"\n",
    "                f\"LIMIT {limit}\"\n",
    "            )\n",
    "            symptoms = [record['symptom'] for record in result]\n",
    "            all_symptoms.extend(symptoms)\n",
    "    return all_symptoms\n",
    "\n",
    "# Example usage\n",
    "search_queries = ['bilateral upper extremity ecchymosses', 'hypotension', 'leukocytosis', 'afib with RVR', 'acute renal failure', 'anemia', 'upper extremity ecchymoses', 'coagulopathy', 'thrombocytopenia', 'elevated white count', 'cryptogenic cirrhosis', 'chronic diastolic CHF', 'GI bleed', 'hypothyroid']\n",
    "search_results = search_symptoms(search_queries)\n",
    "print(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prioritized_relationships(symptom_names, weightage=5, limit=10):\n",
    "    \"\"\"\n",
    "    Retrieves a list of diseases associated with the given symptom names, ordered by the maximum weight of the associations.\n",
    "    \n",
    "    Parameters:\n",
    "    symptom_names (list): A list of symptom names to search for.\n",
    "    weightage (int, optional): The minimum weight threshold for the associations. Defaults to 5.\n",
    "    limit (int, optional): The maximum number of results to return. Defaults to 20.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - codes (list): A list of disease names ordered by maximum association weight.\n",
    "        - all_info (dict): A dictionary mapping disease names to a list containing the disease name and the maximum association weight.\n",
    "    \"\"\"\n",
    "    with driver.session() as session:\n",
    "        result = session.run(f\"\"\"\n",
    "            MATCH (s:Symptom)-[r:ASSOCIATED_WITH]->(d:Disease)\n",
    "            WHERE s.name IN $symptoms AND r.weight >= {weightage}\n",
    "            WITH d.title AS disease_name, collect(s.name) AS symptoms, max(r.weight) AS max_weight\n",
    "            RETURN disease_name, symptoms, max_weight\n",
    "            ORDER BY max_weight DESC\n",
    "            LIMIT {limit}\n",
    "        \"\"\", symptoms=symptom_names)\n",
    "        codes = []\n",
    "        all_info = {}\n",
    "        for record in result:\n",
    "            codes.append(record['disease_name'])\n",
    "            all_info[record['disease_name']] = [record['disease_name'], record['max_weight']]\n",
    "        return codes, all_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PUBMEDKG Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_predictions_with_rag(input_text, symptoms, true_length, threshold=0.8,  model_only = False ):\n",
    "    \"\"\"\n",
    "    Get predictions from the model and refine them using the knowledge graph.\n",
    "    \"\"\"\n",
    "    # Query the KG for related diseases\n",
    "    if model_only :\n",
    "         \n",
    "        augmented_input = f\"{input_text}\"\n",
    "    else : \n",
    "\n",
    "        kg_results = neo4j_handler.query_kg(symptoms, true_length)\n",
    "        augmented_input = f\"{kg_results}\\n{input_text}\"\n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "    # Tokenize and predict using the model\n",
    "    tokenized_input = tokenizer(\n",
    "        augmented_input,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding='max_length'\n",
    "    )\n",
    "    tokenized_input = {k: v.to(device) for k, v in tokenized_input.items()}\n",
    "    output = model(**tokenized_input)\n",
    "    predictions = torch.sigmoid(output.logits)\n",
    "    predicted_labels = [model.config.id2label[_id] for _id in (predictions > threshold).nonzero()[:, 1].tolist()]\n",
    "    \n",
    "    \n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(input_text, threshold = 0.8) : \n",
    "    \"\"\"give the EHR/Symptoms as input, and \n",
    "    get the disease codes (matching in the classes under consideration) \n",
    "    as the output\"\"\"\n",
    "\n",
    "    tokenized_input =  tokenizer(\n",
    "        input_text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512,  # BERT's maximum sequence length\n",
    "        padding='max_length'\n",
    "    )\n",
    "    tokenized_input = {k: v.to(device) for k, v in tokenized_input.items()}\n",
    "    output = model(**tokenized_input)\n",
    "    predictions = torch.sigmoid(output.logits)\n",
    "    predicted_labels = [model.config.id2label[_id] for _id in (predictions > threshold).nonzero()[:, 1].tolist()]\n",
    "    classes = str('403 486 582 585 425 276 710 724 458 287 285 275 583 558 327 228 338 789 790 V451 531 410 414 725 191 331 530 411 482 272 305 194 197 255 424 584 998 682 511 599 428 349 401 V100 V453 V586 041 251 E932 V300 V053 V290 571 070 250 570 572 286 518 038 280 263 995 303 244 112 881 903 955 E956 745 762 441 496 447 440 997 274 427 V104 V101 V120 V090 569 560 491 V458 433 436 493 996 416 V310 765 769 774 770 747 776 772 362 198 V103 746 766 V293 853 780 E888 730 357 430 293 443 V158 396 365 135 311 E935 721 214 437 242 600 189 304 711 800 E814 873 781 378 951 767 431 294 042 V141 V071 764 775 969 295 E950 266 779 355 553 965 E850 E853 426 804 E916 202 V502 398 707 348 787 564 V428 238 300 788 332 V107 V433 E879 861 423 E966 200 555 771 270 335 723 079 851 807 864 865 860 413 782 V108 507 512 752 162 783 778 333 785 136 799 E931 157 574 568 E878 722 719 V125 296 478 V170 805 596 E880 822 733 578 459 438 008 V098 185 967 225 V457 389 412 593 345 201 515 E933 278 492 715 415 V105 535 608 E870 V058 513 709 E821 V173 824 911 913 E812 576 203 281 580 V450 216 V340 579 693 351 088 714 E849 307 421 786 E942 959 E928 588 364 V642 V025 252 283 784 611 622 289 446 729 V498 V456 795 E854 V667 155 V130 882 852 957 E815 466 792 434 342 153 E934 481 910 456 453 867 273 532 806 V422 V541 556 394 444 924 E960 514 763 218 359 340 999 451 324 E939 537 737 455 E884 V427 591 592 577 557 575 356 368 552 500 750 253 292 E937 211 288 773 314 V652 432 379 435 E930 199 V641 494 966 758 E855 741 918 V436 078 562 820 801 839 E881 V584 731 E885 812 156 567 696 501 712 V707 215 754 753 508 876 720 V442 871 958 802 847 397 196 346 E968 510 404 360 376 370 V026 904 928 821 823 150 573 850 V497 E938 V533 V556 728 870 V874 V153 V644 V600 521 301 164 054 344 464 442 V150 282 V08 891 808 866 902 117 484 760 V048 691 519 528 320 369 685 V625 794 793 318 V441 761 936 E915 457 395 053 V113 V632 386 623 290 204 271 E819 811 813 884 E813 751 366 297 V440 473 E910 V420 057 536 152 970 485 235 372 E882 127 160 170 V880 595 909 V443 490 343 319 130 698 E823 246 854 868 872 982 151 V853 980 E980 291 517 268 487 E866 796 V452 036 354 648 701 V063 V038 227 614 533 736 942 E924 240 921 V454 977 759 768 923 E816 681 138 358 950 922 205 990 009 619 417 279 257 E860 755 991 E957 241 810 920 V461 V127 261 429 550 874 756 935 831 718 962 E858 803 480 674 277 880 879 377 529 047 083 835 462 336 E947 V160 420 317 454 E883 840 V550 960 586 933 597 350 E911 742 V614 298 V551 620 716 V462 V180 706 565 452 825 322 154 040 110 605 607 461 704 713 945 052 948 323 325 934 516 039 975 971 994 666 V111 907 E929 566 603 405 049 237 V161 V553 262 743 422 337 625 757 527 309 815 V163 402 869 E912 188 590 V852 V446 E852 886 E919 183 862 875 877 890 E944 E936 V444 598 V552 226 E818 617 E958 V123 748 968 V298 465 972 E826 905 E969 744 E829 V301 388 V146 V151 887 375 334 E848 E918 284 E876 260 987 E890 834 522 692 V588 310 863 E834 192 035 V174 171 738 220 477 212 172 V548 726 526 V099 777 749 E922 952 V320 901 542 449 V011 963 E822 524 V052 V539 144 445 321 380 604 383 587 137 845 695 V496 180 618 V102 540 525 916 174 V628 892 816 V171 520 708 176 791 V854 E906 V714 V554 V435 883 927 V434 007 581 V202 140 642 644 654 V270 V252 193 V838 V555 139 V195 V068 601 826 694 626 956 245 919 299 727 684 647 E941 V850 665 391 308 633 639 V230 V061 223 269 V183 046 534 361 673 643 986 005 034 382 239 232 V169 E901 908 634 836 616 E917 734 V698 133 E887 V445 V155 E949 142 E987 236 470 463 E940 229 448 702 182 E825 V851 814 V881 259 906 161 E891 830 E953 195 093 472 914 E988 930 543 686 900 075 705 939 381 V311 V168 018 004 917 483 656 641 217 V291 V164 E943 134 635 659 E920 506 E869 111 096 094 123 158 141 243 690 097 632 989 964 027 V596 373 V017 254 932 187 353 669 V504 602 843 912 374 983 E864 031 210 114 646 077 V018 670 615 V638 V135 938 V580 680 878 E965 471 652 663 658 V272 213 032 148 V643 V148 V062 E989 E927 131 233 V040 V066 125 V503 V581 V292 V192 700 703 209 V029 208 697 E871 184 015 146 V140 V154 992 249 149 V142 844 175 V542 363 V152 V106 V688 V265 012 885 E955 V530 385 V124 V741 390 474 627 817 230 E817 V198 E862 258 V463 735 V024 V640 976 E861 V765 V023 V626 E828 V188 341 V560 798 V448 893 495 084 523 V653 953 V549 V095 V182 621 475 V425 058 306 V165 551 E831 V136 V109 256 219 221 961 985 828 671 E820 897 V840 926 V421 048 594 896 082 E986 541 145 267 683 V097 732 265 011 E801 V185 664 V620 E840 V166 V468 629 115 V587 E908 120 V708 098 V469 V694 E824 E970 121 838 832 460 013 V239 944 V189 946 118 326 E945 645 352 159 E967 V618 147 V908 941 312 624 V186 V145 661 010 E865 091 E886 649 E905 E962 V612 E959 502 V438 V222 163 947 V162 E946 V716 315 367 V540 846 717 V561 V175 842 V138 V703 V583 841 672 062 488 347 339 E841 086 V400 E985 655 974 V289 V604 V074 V728 371 190 V126 090 143 943 V611 V331 085 V172 E835 668 740 V167 V558 E851 E811 V430 837 V072 V431 302 E923 V110 E900 V562 E963 E964 V118 V624 E800 988 833 023 V020 021 003 V660 E806 313 E954 V860 660 V449 231 V602 186 E863 E874 V721 V181 651 033 V654 E804 330 610 384 E838 E001 973 819 014 132 E899 925 207 V861 E002 E030 E000 894 E873 E999 E976 E003 V016 E805 045 V610 V078 V510 E029 848 E006 V403 122 V536 E013 E019 173 E913 677 E008 V568 V143 V091 V872 066 V601 116 V882 V065 538 V655 316 E007 E016 E921 V902 206 V254 099 V489 V870 E977 628 V250 E982 V486 539 V073 937 V812 030 V271 589 V672 V671 E926 E925 E857 V537 954 E827 657 V910 V789 V037 E975 V045 V848 393 V426 179 387 V903 E856 V901 915').split(' ')\n",
    "\n",
    "    predicted_labels = list(set(classes).intersection(set(predicted_labels)))\n",
    "\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_binary_matrix(labels, classes):\n",
    "    \"\"\"\n",
    "    Creates a binary matrix from a list of labels and a list of classes.\n",
    "\n",
    "    Parameters:\n",
    "    labels (list): A list of lists, where each inner list contains the labels for a single data point.\n",
    "    classes (list): A list of class names.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A binary matrix where each row represents a data point and each column represents a class.\n",
    "    \"\"\"\n",
    "    binary_matrix = np.zeros((len(labels), len(classes)), dtype=int)\n",
    "    for i, label_list in enumerate(labels):\n",
    "        for label in label_list:\n",
    "            if label in classes:\n",
    "                idx = classes.index(label)\n",
    "                binary_matrix[i, idx] = 1\n",
    "    return binary_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "def roc_auc(probs, labels, multilabel=False, average='macro', multi_class='ovo'):\n",
    "    if isinstance(labels, list):\n",
    "        labels = np.array(labels, dtype=int)\n",
    "    else:\n",
    "        labels = labels.astype(int)\n",
    "\n",
    "    # Filter relevant columns if multilabel is True\n",
    "    y_score = probs\n",
    "    if multilabel:\n",
    "        # Identify classes with at least one positive label\n",
    "        present_classes = np.any(labels == 1, axis=0)\n",
    "        labels = labels[:, present_classes]\n",
    "        y_score = np.array(probs)[:, present_classes]\n",
    "\n",
    "    # Calculate ROC AUC score\n",
    "    roc_auc = roc_auc_score(y_true=labels, y_score=y_score, average=average, multi_class=multi_class)\n",
    "\n",
    "    return {\n",
    "        'roc_auc': roc_auc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to calculate precision, recall, and F1 score based on predicted and true disease codes\n",
    "def calculate_f1(true_codes, predicted_codes):\n",
    "    true_prefixes = {code[:3] for code in true_codes}\n",
    "    pred_prefixes = {str(code)[:3] for code in predicted_codes}\n",
    "\n",
    "    # True Positives (TP): Codes correctly predicted\n",
    "    true_positives = len(true_prefixes & pred_prefixes)\n",
    "    \n",
    "    # False Positives (FP): Predicted codes that are not in true codes\n",
    "    false_positives = len(pred_prefixes - true_prefixes)\n",
    "    \n",
    "    # False Negatives (FN): True codes that were not predicted\n",
    "    false_negatives = len(true_prefixes - pred_prefixes)\n",
    "    \n",
    "    # Calculate Precision and Recall\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    \n",
    "    # Calculate F1 Score\n",
    "    if precision + recall == 0:\n",
    "        f1 = 0.0\n",
    "    else:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# my_list = [1, 2, 2, 3, 3, 3, 4, 4, 4, 4]\n",
    "# counts = Counter(my_list)\n",
    "# print(counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import csv, ast\n",
    "import pandas as pd\n",
    "raw_test_df = pd.read_csv('symptoms_test.csv')\n",
    "raw_test_df = raw_test_df.drop('Unnamed: 0',axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>Diseases</th>\n",
       "      <th>id</th>\n",
       "      <th>icd_9_desc</th>\n",
       "      <th>text</th>\n",
       "      <th>long_texts</th>\n",
       "      <th>short_texts</th>\n",
       "      <th>discharge_summary</th>\n",
       "      <th>short_codes</th>\n",
       "      <th>num_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['bilateral upper extremity ecchymosses', 'hyp...</td>\n",
       "      <td>['cryptogenic cirrhosis', 'afib/SSS', 'fatty l...</td>\n",
       "      <td>155525</td>\n",
       "      <td>Unspecified septicemia,Septic shock,Pneumoniti...</td>\n",
       "      <td>CHIEF COMPLAINT: L. hand hematoma\\n\\nPRESENT I...</td>\n",
       "      <td>Unspecified septicemia,Septic shock,Pneumoniti...</td>\n",
       "      <td>Septicemia NOS,Septic shock,Food/vomit pneumon...</td>\n",
       "      <td>Admission Date:  [**2171-8-2**]              D...</td>\n",
       "      <td>038,785,507,518,584,348,511,456,572,285,428,27...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['altered mental status', 'GI bleed', 'hypoten...</td>\n",
       "      <td>['neurofibromatosis', 'HTN', 'hyperlipidemia',...</td>\n",
       "      <td>187452</td>\n",
       "      <td>Streptococcal septicemia,Septic shock,Acute re...</td>\n",
       "      <td>CHIEF COMPLAINT: altered mental status, GI ble...</td>\n",
       "      <td>Streptococcal septicemia,Septic shock,Acute re...</td>\n",
       "      <td>Streptococcal septicemia,Septic shock,Acute re...</td>\n",
       "      <td>Admission Date:  [**2172-9-8**]              D...</td>\n",
       "      <td>038,785,518,584,349,577,276,997,533,576,599,00...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['abdominal pain', 'nonbloody emesis', 'hypote...</td>\n",
       "      <td>['Nonischemic dilated cardiomyopathy', 'hypert...</td>\n",
       "      <td>161002</td>\n",
       "      <td>Acute pancreatitis,Acute kidney failure with l...</td>\n",
       "      <td>CHIEF COMPLAINT: abdominal pain\\n\\nPRESENT ILL...</td>\n",
       "      <td>Acute pancreatitis,Acute kidney failure with l...</td>\n",
       "      <td>Acute pancreatitis,Ac kidny fail, tubr necr,Se...</td>\n",
       "      <td>Admission Date:  [**2135-4-4**]              D...</td>\n",
       "      <td>577,584,038,995,410,785,518,567,425,070,576,27...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['bloody diarrhea', 'abdominal pain', 'intermi...</td>\n",
       "      <td>['mesenteric ischemia', 'bowel ischemia', 'atr...</td>\n",
       "      <td>119210</td>\n",
       "      <td>Infectious colitis, enteritis, and gastroenter...</td>\n",
       "      <td>CHIEF COMPLAINT: Mesenteric Ischemia\\n\\nPRESEN...</td>\n",
       "      <td>Infectious colitis, enteritis, and gastroenter...</td>\n",
       "      <td>Infectious enteritis NOS,Chr stomach ulc w hem...</td>\n",
       "      <td>Admission Date:  [**2136-2-9**]              D...</td>\n",
       "      <td>009,531,532,038,482,995,785,584,577,518,449,44...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['abdominal pain', 'hypotension', 'decreased P...</td>\n",
       "      <td>['HTN', 'Type 2 DM', 'recent recurrent cholecy...</td>\n",
       "      <td>182497</td>\n",
       "      <td>Unspecified septicemia,Toxic encephalopathy,Ot...</td>\n",
       "      <td>CHIEF COMPLAINT: abdominal pain\\n\\nPRESENT ILL...</td>\n",
       "      <td>Unspecified septicemia,Toxic encephalopathy,Ot...</td>\n",
       "      <td>Septicemia NOS,Toxic encephalopathy,Ascites NE...</td>\n",
       "      <td>Admission Date:  [**2104-5-20**]              ...</td>\n",
       "      <td>038,349,789,276,599,286,511,575,041,995,783,57...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Symptoms  \\\n",
       "0  ['bilateral upper extremity ecchymosses', 'hyp...   \n",
       "1  ['altered mental status', 'GI bleed', 'hypoten...   \n",
       "2  ['abdominal pain', 'nonbloody emesis', 'hypote...   \n",
       "3  ['bloody diarrhea', 'abdominal pain', 'intermi...   \n",
       "4  ['abdominal pain', 'hypotension', 'decreased P...   \n",
       "\n",
       "                                            Diseases      id  \\\n",
       "0  ['cryptogenic cirrhosis', 'afib/SSS', 'fatty l...  155525   \n",
       "1  ['neurofibromatosis', 'HTN', 'hyperlipidemia',...  187452   \n",
       "2  ['Nonischemic dilated cardiomyopathy', 'hypert...  161002   \n",
       "3  ['mesenteric ischemia', 'bowel ischemia', 'atr...  119210   \n",
       "4  ['HTN', 'Type 2 DM', 'recent recurrent cholecy...  182497   \n",
       "\n",
       "                                          icd_9_desc  \\\n",
       "0  Unspecified septicemia,Septic shock,Pneumoniti...   \n",
       "1  Streptococcal septicemia,Septic shock,Acute re...   \n",
       "2  Acute pancreatitis,Acute kidney failure with l...   \n",
       "3  Infectious colitis, enteritis, and gastroenter...   \n",
       "4  Unspecified septicemia,Toxic encephalopathy,Ot...   \n",
       "\n",
       "                                                text  \\\n",
       "0  CHIEF COMPLAINT: L. hand hematoma\\n\\nPRESENT I...   \n",
       "1  CHIEF COMPLAINT: altered mental status, GI ble...   \n",
       "2  CHIEF COMPLAINT: abdominal pain\\n\\nPRESENT ILL...   \n",
       "3  CHIEF COMPLAINT: Mesenteric Ischemia\\n\\nPRESEN...   \n",
       "4  CHIEF COMPLAINT: abdominal pain\\n\\nPRESENT ILL...   \n",
       "\n",
       "                                          long_texts  \\\n",
       "0  Unspecified septicemia,Septic shock,Pneumoniti...   \n",
       "1  Streptococcal septicemia,Septic shock,Acute re...   \n",
       "2  Acute pancreatitis,Acute kidney failure with l...   \n",
       "3  Infectious colitis, enteritis, and gastroenter...   \n",
       "4  Unspecified septicemia,Toxic encephalopathy,Ot...   \n",
       "\n",
       "                                         short_texts  \\\n",
       "0  Septicemia NOS,Septic shock,Food/vomit pneumon...   \n",
       "1  Streptococcal septicemia,Septic shock,Acute re...   \n",
       "2  Acute pancreatitis,Ac kidny fail, tubr necr,Se...   \n",
       "3  Infectious enteritis NOS,Chr stomach ulc w hem...   \n",
       "4  Septicemia NOS,Toxic encephalopathy,Ascites NE...   \n",
       "\n",
       "                                   discharge_summary  \\\n",
       "0  Admission Date:  [**2171-8-2**]              D...   \n",
       "1  Admission Date:  [**2172-9-8**]              D...   \n",
       "2  Admission Date:  [**2135-4-4**]              D...   \n",
       "3  Admission Date:  [**2136-2-9**]              D...   \n",
       "4  Admission Date:  [**2104-5-20**]              ...   \n",
       "\n",
       "                                         short_codes  num_codes  \n",
       "0  038,785,507,518,584,348,511,456,572,285,428,27...         37  \n",
       "1  038,785,518,584,349,577,276,997,533,576,599,00...         35  \n",
       "2  577,584,038,995,410,785,518,567,425,070,576,27...         34  \n",
       "3  009,531,532,038,482,995,785,584,577,518,449,44...         34  \n",
       "4  038,349,789,276,599,286,511,575,041,995,783,57...         34  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ =  str(raw_test_df.iloc[0].Symptoms)+ '\\n' + str(raw_test_df.iloc[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['bilateral upper extremity ecchymosses', 'hypotension', 'leukocytosis', 'afib with RVR', 'acute renal failure', 'anemia', 'upper extremity ecchymoses', 'coagulopathy', 'thrombocytopenia', 'elevated white count', 'cryptogenic cirrhosis', 'chronic diastolic CHF', 'GI bleed', 'hypothyroid']\\nCHIEF COMPLAINT: L. hand hematoma\\n\\nPRESENT ILLNESS: Mr [**Known lastname 9780**] is an 84 yo M with a history of cryptogenic cirrhosis\\n(c/b variceal bleed requiring [**Last Name (un) 10045**]/TIPS [**2171-7-9**]) and\\nafib/SSS (s/p dual chamber PPM) who was recently admitted from\\n[**Date range (1) 108604**] with UGI bleed and who was admitted this time on\\n[**2171-8-2**] with bilateral upper extremity ecchymosses that occurred\\nin the setting of therapeutic enoxaparin. He had some falls at\\nrehab but according to his wife these occurred after he already\\nhad the bruises. A trauma workup in the ED was notable mainly\\nfor a hematocrit drop of 30.3 at last dishcarge -> 23.7. He had\\nOB+ brown stool, negative NG lavage. It was felt that drop in\\nHCT was most likely related to arm.\\nHe was admitted to the medical floor. Yesterday ([**8-3**]) his HCT\\nhad further dropped to 20.0 and he was transfused 2 units of\\npRBCs with appropriate increase to 26.0. He had loose stools\\n(but is on lactulose) which were reportedly not melanotic but\\nguiac positive. Early this morning ([**8-4**]) the patient was noted\\nto be in afib with RVR to the 150s which was asyptomatic. His\\nblood pressure dropped to 80s/doppler from systolic 110s at\\nbaseline. He has not had any fevers but has had a leukocytosis\\nsince admission. He denies cough or urinary symptoms. He was\\ntherefore transferred to the MICU for management of his afib\\nwith hypotension.\\n\\nMEDICAL HISTORY: 1. Hypertension.\\n2. Sick sinus syndrome with atrial fibrillation s/p Dual Chamber\\nPacemaker ([**Company 1543**] Revo MRI RVDR01).\\n3. Complications of pacemaker insertion in the past.\\n4. Fatty liver disease.\\n5. Cryptogenic cirrhosis with portal hypertension and varices\\ns/p TIPS on [**2171-7-9**].\\n6. Upper gastrointestinal bleed from AV malformations in the\\nduodenum in [**2169**].\\n7. Chronic anemia, bone marrow suppression, baseline hematocrit\\n\\nMEDICATION ON ADMISSION: Preadmission medications listed are correct and complete.\\nInformation was obtained from PatientwebOMR.\\n1. Enoxaparin Sodium 90 mg SC BID\\n2. Diltiazem 60 mg PO QID\\nhold for SBP<100, HR<60\\n3. Ferrous Sulfate 325 mg PO DAILY\\n4. Furosemide 20 mg PO BID\\nhold for SBP<100\\n5. Lactulose 30 mL PO TID\\ntitrate to [**2-10**] BMs per day\\n6. Levothyroxine Sodium 150 mcg PO DAILY\\n7. Multivitamins 1 TAB PO DAILY\\n8. Rifaximin 550 mg PO BID\\n9. Pantoprazole 40 mg PO Q12H\\n10. Atorvastatin 5 mg PO DAILY\\n11. Artificial Tear Ointment 1 Appl BOTH EYES PRN dry eyes\\n12. Fluticasone-Salmeterol Diskus (250/50)  1 INH IH DAILY\\n\\nALLERGIES: Coumadin / Heparin Agents\\n\\nPHYSICAL EXAM: ADMISSION PHYSICAL EXAM:\\nVS: 97.8 140/67 96 18 98% RA\\nGEN comfortable in no acute distress\\nHEENT NCAT dry MM, sclera anicteric, OP clear\\nNECK supple, no LAD\\nPULM Good aeration, CTAB no wheezes, rales, ronchi\\nCV RRR normal S1/S2, 2/6 systolic murmur at LLSB\\nABD soft NT ND normoactive bowel sounds, no r/g\\nEXT: LUE with bruising and swelling from mid humerous distally.\\nROM at shoulder, elbow and wrist limited by pain and swelling.\\ndistal pulse palpable. sensation grossly intact. RUE noted to\\nhave hematoma over wrist with bandage in place and otherwise\\nNVI. trace LE edema.\\nNEURO: confused and slow to respond. no asterixis\\n\\nFAMILY HISTORY: [**Name (NI) **] father had a stroke at age 63, mother died of unknown\\ncauses at 83.\\n\\nSOCIAL HISTORY: Was living with his wife in an assisted-living facility although\\nhe recently has been in and out of rehab. He is a retired [**University/College **]\\nprofessor of chemical process engineering. He stopped smoking 40\\nyears\\nago. Has a 30 pack year history of smoking. Takes 2 ounces of\\nalcohol a week. He uses a cane to ambulate.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['puerperal fever', 'intermittent fever']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_query = search_symptoms(['fever'], limit = 2)\n",
    "expanded_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neo4j_handler.query_kg(['fever', 'feverish'], true_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.makedirs('infer_llm_22')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from weaviate.connect import ConnectionParams\n",
    "\n",
    "def mimic_train_datasets(client, text, top_n=2) : \n",
    "\n",
    "\n",
    "   \n",
    "    # Get the collection\n",
    "    collection = client.collections.get(\"MedicalRecords_v3\")\n",
    "\n",
    "    # Perform a BM25 search\n",
    "    response = collection.query.bm25(\n",
    "        query=f\"{text}\",\n",
    "        limit=top_n\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Print results\n",
    "    for item in response.objects:\n",
    "        symptoms = item.properties['symptoms']\n",
    "        codes = list(item.properties['short_codes'].split(','))\n",
    "        icd_9_codes = [i[:3] for i in codes]\n",
    "        text = item.properties['text']\n",
    "\n",
    "        results.append((symptoms, icd_9_codes, text))\n",
    "        \n",
    "    \n",
    "    return results\n",
    "   \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the LLama 70b Model. \n",
    "Case 1 : Base Model on MIMIC IV symptoms + notes\n",
    "Case 2 : Base Model + KG  on MIMIC Symptoms + notes\n",
    "Case 3 : Fine tuned model (smaller) on Mimic symptoms + notes\n",
    "Case 4 : Base Model + KG on MIMIC Symptoms + notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>SHORT_CODES</th>\n",
       "      <th>text</th>\n",
       "      <th>note_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>CHIEF_COMPLAINT</th>\n",
       "      <th>PRESENT_ILLNESS</th>\n",
       "      <th>MEDICAL_HISTORY</th>\n",
       "      <th>MEDICATION_ADM</th>\n",
       "      <th>ALLERGIES</th>\n",
       "      <th>PHYSICAL_EXAM</th>\n",
       "      <th>FAMILY_HISTORY</th>\n",
       "      <th>SOCIAL_HISTORY</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>Symptoms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>29461342</td>\n",
       "      <td>287,415,432,311,173,530,288,790,V586</td>\n",
       "      <td>Name:  ___                   Unit No:   ___\\n ...</td>\n",
       "      <td>13481293-DS-21</td>\n",
       "      <td>13481293</td>\n",
       "      <td>2182-10-05 00:00:00</td>\n",
       "      <td>Chest/ABD pain, SOB\\n \\nMajor Surgical or Inva...</td>\n",
       "      <td>HISTORY OF PRESENT ILLNESS: ___ with h/o ITP p...</td>\n",
       "      <td>ITP (recently diagnosed in ___\\nDepression\\nFo...</td>\n",
       "      <td>The Preadmission Medication list is accurate a...</td>\n",
       "      <td>Ciprofloxacin\\n \\nAttending: ___.\\n \\nChief Co...</td>\n",
       "      <td>Vitals: T97.9, BP119/79, HR 48, RR 18, 100/RA ...</td>\n",
       "      <td>Her father died at age ___ of myocardial infar...</td>\n",
       "      <td>___\\nFamily History:\\nHer father died at age _...</td>\n",
       "      <td>CHIEF COMPLAINT: Chest/ABD pain, SOB\\n \\nMajor...</td>\n",
       "      <td>['Chest pain', 'Abdominal pain', 'Shortness of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>21981089</td>\n",
       "      <td>157,576,038,995,518,155,578,285,293,V667,427,0...</td>\n",
       "      <td>Name:  ___                 Unit No:   ___\\n \\n...</td>\n",
       "      <td>11094046-DS-12</td>\n",
       "      <td>11094046</td>\n",
       "      <td>2126-05-11 00:00:00</td>\n",
       "      <td>Distal cholangiocarcinoma versus pancreatic ad...</td>\n",
       "      <td>___ y.o. M presenting with 3 wks of painless j...</td>\n",
       "      <td>HCV, Dislipidemia, COPD, Arthritis/Gout, Type ...</td>\n",
       "      <td>Glipizide XL 5', Avodart 0.5', B12, Zantac 300...</td>\n",
       "      <td>Food Extracts\\n \\nAttending: ___.\\n \\nChief Co...</td>\n",
       "      <td>On Admission:\\nVitals-98.3  70  130/70  15  10...</td>\n",
       "      <td>Noncontributory\\n \\nPhysical Exam:\\nOn Admissi...</td>\n",
       "      <td>___\\nFamily History:\\nNoncontributory\\n \\nPhys...</td>\n",
       "      <td>CHIEF COMPLAINT: Distal cholangiocarcinoma ver...</td>\n",
       "      <td>['painless jaundice', 'loss of appetite', 'wei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>26760780</td>\n",
       "      <td>780,784,724,723,331,E888,E849,722,787,782,729,...</td>\n",
       "      <td>Name:  ___                Unit No:   ___\\n \\nA...</td>\n",
       "      <td>18743501-DS-19</td>\n",
       "      <td>18743501</td>\n",
       "      <td>2132-03-30 00:00:00</td>\n",
       "      <td>Neck pain, arm numbness, weakness</td>\n",
       "      <td>___ female with history of anxiety presenting ...</td>\n",
       "      <td>hypothyroidism, post ablative. \\nmigraines\\ns/...</td>\n",
       "      <td>The Preadmission Medication list is accurate a...</td>\n",
       "      <td>Methimazole / sertraline / tramadol\\n \\nAttend...</td>\n",
       "      <td>ON ADMISSION:\\nVitals - T: 97.9 BP: 104/65 HR:...</td>\n",
       "      <td>Diabetes\\nHTN\\n \\nPhysical Exam:\\nON ADMISSION...</td>\n",
       "      <td>___\\nFamily History:\\nDiabetes\\nHTN\\n \\nPhysic...</td>\n",
       "      <td>CHIEF COMPLAINT: Neck pain, arm numbness, weak...</td>\n",
       "      <td>['Neck pain', 'Arm numbness', 'Weakness', 'Nau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>25559692</td>\n",
       "      <td>786,289,401,272,296,V104,V125,V586</td>\n",
       "      <td>Name:  ___                 Unit No:   ___\\n \\n...</td>\n",
       "      <td>18024139-DS-16</td>\n",
       "      <td>18024139</td>\n",
       "      <td>2166-01-13 00:00:00</td>\n",
       "      <td>chest pain\\n \\nMajor Surgical or Invasive Proc...</td>\n",
       "      <td>Ms. ___ is a ___ year old female who presents ...</td>\n",
       "      <td>1. Confirmed Pulmonary Embolus (per ___ E.D.) ...</td>\n",
       "      <td>Amlodipine 5mg daily  \\nAripiprazole 10 mg dai...</td>\n",
       "      <td>Latex / Toradol / Monistat 1 / Haldol / Biaxin...</td>\n",
       "      <td>sat: 100% 2L, pain ___  \\n___: Anxious female ...</td>\n",
       "      <td>Her grandmother died of ovarian cancer. Her fa...</td>\n",
       "      <td>___\\nFamily History:\\nHer grandmother died of ...</td>\n",
       "      <td>CHIEF COMPLAINT: chest pain\\n \\nMajor Surgical...</td>\n",
       "      <td>['chest pain', 'left-sided chest pain radiatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>21887944</td>\n",
       "      <td>435,784,338,311,300,V125,401,305,780</td>\n",
       "      <td>Name:  ___              Unit No:   ___\\n \\nAdm...</td>\n",
       "      <td>14574668-DS-3</td>\n",
       "      <td>14574668</td>\n",
       "      <td>2121-06-29 00:00:00</td>\n",
       "      <td>Acute-on-chronic HA in setting of RCVS</td>\n",
       "      <td>___ RHF recently admitted from ___ - ___ for\\n...</td>\n",
       "      <td>- RCVS\\n  * seizure\\n  * SAH\\n  * stroke\\n- Mi...</td>\n",
       "      <td>The Preadmission Medication list is accurate a...</td>\n",
       "      <td>No Known Allergies / Adverse Drug Reactions\\n ...</td>\n",
       "      <td>On Admission:\\nVitals: 10 98.1 90 107/66 16 99...</td>\n",
       "      <td>Sister had a brain bleed, father had his first...</td>\n",
       "      <td>___\\nFamily History:\\nSister had a brain bleed...</td>\n",
       "      <td>CHIEF COMPLAINT: Acute-on-chronic HA in settin...</td>\n",
       "      <td>['Acute-on-chronic headache', 'Nausea', 'Vomit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   hadm_id                                        SHORT_CODES  \\\n",
       "0           0  29461342               287,415,432,311,173,530,288,790,V586   \n",
       "1           1  21981089  157,576,038,995,518,155,578,285,293,V667,427,0...   \n",
       "2           2  26760780  780,784,724,723,331,E888,E849,722,787,782,729,...   \n",
       "3           3  25559692                 786,289,401,272,296,V104,V125,V586   \n",
       "4           4  21887944               435,784,338,311,300,V125,401,305,780   \n",
       "\n",
       "                                                text         note_id  \\\n",
       "0  Name:  ___                   Unit No:   ___\\n ...  13481293-DS-21   \n",
       "1  Name:  ___                 Unit No:   ___\\n \\n...  11094046-DS-12   \n",
       "2  Name:  ___                Unit No:   ___\\n \\nA...  18743501-DS-19   \n",
       "3  Name:  ___                 Unit No:   ___\\n \\n...  18024139-DS-16   \n",
       "4  Name:  ___              Unit No:   ___\\n \\nAdm...   14574668-DS-3   \n",
       "\n",
       "   subject_id            charttime  \\\n",
       "0    13481293  2182-10-05 00:00:00   \n",
       "1    11094046  2126-05-11 00:00:00   \n",
       "2    18743501  2132-03-30 00:00:00   \n",
       "3    18024139  2166-01-13 00:00:00   \n",
       "4    14574668  2121-06-29 00:00:00   \n",
       "\n",
       "                                     CHIEF_COMPLAINT  \\\n",
       "0  Chest/ABD pain, SOB\\n \\nMajor Surgical or Inva...   \n",
       "1  Distal cholangiocarcinoma versus pancreatic ad...   \n",
       "2                  Neck pain, arm numbness, weakness   \n",
       "3  chest pain\\n \\nMajor Surgical or Invasive Proc...   \n",
       "4             Acute-on-chronic HA in setting of RCVS   \n",
       "\n",
       "                                     PRESENT_ILLNESS  \\\n",
       "0  HISTORY OF PRESENT ILLNESS: ___ with h/o ITP p...   \n",
       "1  ___ y.o. M presenting with 3 wks of painless j...   \n",
       "2  ___ female with history of anxiety presenting ...   \n",
       "3  Ms. ___ is a ___ year old female who presents ...   \n",
       "4  ___ RHF recently admitted from ___ - ___ for\\n...   \n",
       "\n",
       "                                     MEDICAL_HISTORY  \\\n",
       "0  ITP (recently diagnosed in ___\\nDepression\\nFo...   \n",
       "1  HCV, Dislipidemia, COPD, Arthritis/Gout, Type ...   \n",
       "2  hypothyroidism, post ablative. \\nmigraines\\ns/...   \n",
       "3  1. Confirmed Pulmonary Embolus (per ___ E.D.) ...   \n",
       "4  - RCVS\\n  * seizure\\n  * SAH\\n  * stroke\\n- Mi...   \n",
       "\n",
       "                                      MEDICATION_ADM  \\\n",
       "0  The Preadmission Medication list is accurate a...   \n",
       "1  Glipizide XL 5', Avodart 0.5', B12, Zantac 300...   \n",
       "2  The Preadmission Medication list is accurate a...   \n",
       "3  Amlodipine 5mg daily  \\nAripiprazole 10 mg dai...   \n",
       "4  The Preadmission Medication list is accurate a...   \n",
       "\n",
       "                                           ALLERGIES  \\\n",
       "0  Ciprofloxacin\\n \\nAttending: ___.\\n \\nChief Co...   \n",
       "1  Food Extracts\\n \\nAttending: ___.\\n \\nChief Co...   \n",
       "2  Methimazole / sertraline / tramadol\\n \\nAttend...   \n",
       "3  Latex / Toradol / Monistat 1 / Haldol / Biaxin...   \n",
       "4  No Known Allergies / Adverse Drug Reactions\\n ...   \n",
       "\n",
       "                                       PHYSICAL_EXAM  \\\n",
       "0  Vitals: T97.9, BP119/79, HR 48, RR 18, 100/RA ...   \n",
       "1  On Admission:\\nVitals-98.3  70  130/70  15  10...   \n",
       "2  ON ADMISSION:\\nVitals - T: 97.9 BP: 104/65 HR:...   \n",
       "3  sat: 100% 2L, pain ___  \\n___: Anxious female ...   \n",
       "4  On Admission:\\nVitals: 10 98.1 90 107/66 16 99...   \n",
       "\n",
       "                                      FAMILY_HISTORY  \\\n",
       "0  Her father died at age ___ of myocardial infar...   \n",
       "1  Noncontributory\\n \\nPhysical Exam:\\nOn Admissi...   \n",
       "2  Diabetes\\nHTN\\n \\nPhysical Exam:\\nON ADMISSION...   \n",
       "3  Her grandmother died of ovarian cancer. Her fa...   \n",
       "4  Sister had a brain bleed, father had his first...   \n",
       "\n",
       "                                      SOCIAL_HISTORY  \\\n",
       "0  ___\\nFamily History:\\nHer father died at age _...   \n",
       "1  ___\\nFamily History:\\nNoncontributory\\n \\nPhys...   \n",
       "2  ___\\nFamily History:\\nDiabetes\\nHTN\\n \\nPhysic...   \n",
       "3  ___\\nFamily History:\\nHer grandmother died of ...   \n",
       "4  ___\\nFamily History:\\nSister had a brain bleed...   \n",
       "\n",
       "                                                TEXT  \\\n",
       "0  CHIEF COMPLAINT: Chest/ABD pain, SOB\\n \\nMajor...   \n",
       "1  CHIEF COMPLAINT: Distal cholangiocarcinoma ver...   \n",
       "2  CHIEF COMPLAINT: Neck pain, arm numbness, weak...   \n",
       "3  CHIEF COMPLAINT: chest pain\\n \\nMajor Surgical...   \n",
       "4  CHIEF COMPLAINT: Acute-on-chronic HA in settin...   \n",
       "\n",
       "                                            Symptoms  \n",
       "0  ['Chest pain', 'Abdominal pain', 'Shortness of...  \n",
       "1  ['painless jaundice', 'loss of appetite', 'wei...  \n",
       "2  ['Neck pain', 'Arm numbness', 'Weakness', 'Nau...  \n",
       "3  ['chest pain', 'left-sided chest pain radiatin...  \n",
       "4  ['Acute-on-chronic headache', 'Nausea', 'Vomit...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mimic_4_df = pd.read_csv('mimic-iv-preprocessed-icd-symptoms.csv')\n",
    "mimic_4_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in tqdm(mimic_4_df.iterrows(), total=len(mimic_4_df)):\n",
    "    symptom_list = ast.literal_eval(j[\"Symptoms\"])\n",
    "    true_label = j.SHORT_CODES.split(',')\n",
    "    true_length = len(true_label)\n",
    "    # kg_results = neo4j_handler.query_kg(symptom_list, 22)\n",
    "    #disease_codes = [i['disease'][:3] for i in kg_results]\n",
    "\n",
    "    input_ =  '\\n' +  str(j.Symptoms)+ '\\n'  + str(j.text) #+ str(disease_codes) \n",
    "    output = get_icd9_codes_mistral(prompt_creation(input_), output_dir = '')\n",
    "    outputs.append(output)\n",
    "\n",
    "    processed_data = preprocess_icd9_codes(output, j.note_id)\n",
    "\n",
    "    if i==500:\n",
    "        break\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in tqdm(mimic_4_df.iterrows(), total=len(mimic_4_df)):\n",
    "\n",
    "    symptom_list = ast.literal_eval(j[\"Symptoms\"])\n",
    "    true_label = j.SHORT_CODES.split(',')\n",
    "    true_length = len(true_label)\n",
    "    kg_results = neo4j_handler.query_kg(symptom_list, 22)\n",
    "    disease_codes = [i['disease'][:3] for i in kg_results]\n",
    "\n",
    "    input_ = str(disease_codes) + '\\n' +  str(j.Symptoms)+ '\\n'  + str(j.text) #+ str(disease_codes) \n",
    "    output = get_icd9_codes_mistral(prompt_creation(input_))\n",
    "    outputs.append(output)\n",
    "\n",
    "    processed_data = preprocess_icd9_codes(output, j.note_id, output_dir = 'infer_llm_mimic_4_kg')\n",
    "\n",
    "    if i==500:\n",
    "        break\n",
    "\n",
    "    \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('infer_llm_mimic_4_kg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir('infer_llm_mimic_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_4_df['SHORT_CODES'] = mimic_4_df['SHORT_CODES'].apply(lambda x : x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_4_df  = mimic_4_df.drop('Unnamed: 0',axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "for i in os.listdir('infer_llm_mimic_4_kg'):\n",
    "    with open(f'infer_llm_mimic_4_kg/{i}', 'r') as f:\n",
    "        note_id = i.split('icd9_codes_processed_')[1].split('.json')[0]\n",
    "       \n",
    "        data = json.loads(f.read())\n",
    "        pred_codes = [i['code'] for i in data['icd9_codes']]\n",
    "\n",
    "\n",
    "    # print(list(mimic_4_df[mimic_4_df.note_id == note_id].SHORT_CODES)[0])\n",
    "    true_codes = list(mimic_4_df[mimic_4_df.note_id == note_id].SHORT_CODES)[0].split(',')\n",
    "\n",
    "    true_labels.append(true_codes)\n",
    "    pred_labels.append(pred_codes)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 350)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_labels), len(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores , prec, rec = [], [], []\n",
    "for true_label,pred_label in zip(true_labels, pred_labels) : \n",
    "    precision, recall, f1 = calculate_f1(true_label, pred_label)\n",
    "    f1_scores.append(f1)\n",
    "    prec.append(precision)\n",
    "    rec.append(recall)\n",
    "\n",
    "macro_f1_score = sum(f1_scores) / len(f1_scores)\n",
    "macro_prec = sum(prec) / len(prec)\n",
    "macro_rec = sum(rec) / len(rec)\n",
    "print(f\"Macro Precision Score: {macro_prec:.4f}\")\n",
    "print(f\"Macro Recall Score: {macro_rec:.4f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mimic-4  + rag (mimic-3-train) + llama70b\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('infer_llm_mimic_rag_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = weaviate.connect_to_local(\n",
    "        port=9000,      # Custom HTTP port\n",
    "        grpc_port=9001  # Custom gRPC port\n",
    "    )\n",
    "\n",
    "# Verify connection\n",
    "print(f\"Client is ready: {client.is_ready()}\")\n",
    "    \n",
    "\n",
    "for i, j in tqdm(mimic_4_df.iterrows(), total=len(mimic_4_df)):\n",
    "    if i<210:\n",
    "        continue\n",
    "    symptom_list = ast.literal_eval(j[\"Symptoms\"])\n",
    "    true_label = j.SHORT_CODES.split(',')\n",
    "    true_length = len(true_label)\n",
    "    text = j.TEXT\n",
    "    # kg_results = neo4j_handler.query_kg(symptom_list, 22)\n",
    "    #disease_codes = [i['disease'][:3] for i in kg_results]\n",
    "\n",
    "    results  = mimic_train_datasets(client,text, top_n=5)\n",
    "\n",
    "    input_ =  '\\n' +  str(j.Symptoms)+ '\\n'  + str(j.text) #+ str(disease_codes) \n",
    "    output = get_icd9_codes_mistral(prompt_creation_rag(input_, results))\n",
    "\n",
    "    processed_data = preprocess_icd9_codes(output, j.note_id, output_dir='infer_llm_mimic_rag_5')\n",
    "\n",
    "    if i==500:\n",
    "        break\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "for i in os.listdir('infer_llm_mimic_rag_5'):\n",
    "    with open(f'infer_llm_mimic_rag_5/{i}', 'r') as f:\n",
    "        note_id = i.split('icd9_codes_processed_')[1].split('.json')[0]\n",
    "       \n",
    "        data = json.loads(f.read())\n",
    "        pred_codes = [i['code'] for i in data['icd9_codes']]\n",
    "\n",
    "\n",
    "    # print(list(mimic_4_df[mimic_4_df.note_id == note_id].SHORT_CODES)[0])\n",
    "    true_codes = list(mimic_4_df[mimic_4_df.note_id == note_id].SHORT_CODES)[0].split(',')\n",
    "\n",
    "    true_labels.append(true_codes)\n",
    "    pred_labels.append(pred_codes)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251, 251)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_labels), len(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores , prec, rec = [], [], []\n",
    "for true_label,pred_label in zip(true_labels, pred_labels) : \n",
    "    precision, recall, f1 = calculate_f1(true_label, pred_label)\n",
    "    f1_scores.append(f1)\n",
    "    prec.append(precision)\n",
    "    rec.append(recall)\n",
    "\n",
    "macro_f1_score = sum(f1_scores) / len(f1_scores)\n",
    "macro_prec = sum(prec) / len(prec)\n",
    "macro_rec = sum(rec) / len(rec)\n",
    "print(f\"Macro Precision Score: {macro_prec:.4f}\")\n",
    "print(f\"Macro Recall Score: {macro_rec:.4f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mimic-4  + rag (mimic-3-train) + llama70b + KB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('infer_llm_mimic_rag_kg_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = weaviate.connect_to_local(\n",
    "        port=9000,      # Custom HTTP port\n",
    "        grpc_port=9001  # Custom gRPC port\n",
    "    )\n",
    "\n",
    "# Verify connection\n",
    "print(f\"Client is ready: {client.is_ready()}\")\n",
    "    \n",
    "\n",
    "for i, j in tqdm(mimic_4_df.iterrows(), total=len(mimic_4_df)):\n",
    "    if i<345:\n",
    "        continue\n",
    "    symptom_list = ast.literal_eval(j[\"Symptoms\"])\n",
    "    true_label = j.SHORT_CODES.split(',')\n",
    "    true_length = len(true_label)\n",
    "    text = j.TEXT\n",
    "    kg_results = neo4j_handler.query_kg(symptom_list, 22)\n",
    "    disease_codes = [i['disease'][:3] for i in kg_results]\n",
    "\n",
    "    results  = mimic_train_datasets(client,text, top_n=5)\n",
    "\n",
    "    input_ =    str(j.Symptoms)+ '\\n'  + str(j.text) + '\\n' + str(disease_codes) \n",
    "    output = get_icd9_codes_mistral(prompt_creation_rag(input_, results))\n",
    "\n",
    "    processed_data = preprocess_icd9_codes(output, j.note_id, output_dir='infer_llm_mimic_rag_kg_5')\n",
    "\n",
    "    if i==500:\n",
    "        break\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "for i in os.listdir('infer_llm_mimic_rag_kg_5'):\n",
    "    with open(f'infer_llm_mimic_rag_kg_5/{i}', 'r') as f:\n",
    "        note_id = i.split('icd9_codes_processed_')[1].split('.json')[0]\n",
    "       \n",
    "        data = json.loads(f.read())\n",
    "        pred_codes = [i['code'] for i in data['icd9_codes']]\n",
    "\n",
    "\n",
    "    # print(list(mimic_4_df[mimic_4_df.note_id == note_id].SHORT_CODES)[0])\n",
    "    true_codes = list(mimic_4_df[mimic_4_df.note_id == note_id].SHORT_CODES)[0].split(',')\n",
    "\n",
    "    true_labels.append(true_codes)\n",
    "    pred_labels.append(pred_codes)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233, 233)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_labels), len(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en(true_labels), len(pred_labels)\n",
    "f1_scores , prec, rec = [], [], []\n",
    "for true_label,pred_label in zip(true_labels, pred_labels) : \n",
    "    precision, recall, f1 = calculate_f1(true_label, pred_label)\n",
    "    f1_scores.append(f1)\n",
    "    prec.append(precision)\n",
    "    rec.append(recall)\n",
    "\n",
    "macro_f1_score = sum(f1_scores) / len(f1_scores)\n",
    "macro_prec = sum(prec) / len(prec)\n",
    "macro_rec = sum(rec) / len(rec)\n",
    "print(f\"Macro Precision Score: {macro_prec:.4f}\")\n",
    "print(f\"Macro Recall Score: {macro_rec:.4f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in tqdm(raw_test_df.iterrows(), total=len(raw_test_df)):\n",
    "    symptom_list = ast.literal_eval(j[\"Symptoms\"])\n",
    "    true_label = j.short_codes.split(',')\n",
    "    true_length = len(true_label)\n",
    "    kg_results = neo4j_handler.query_kg(symptom_list, 22)\n",
    "    disease_codes = [i['disease'][:3] for i in kg_results]\n",
    "\n",
    "    input_ =  str(j.Symptoms)+ '\\n' +str(disease_codes)  + '\\n' + str(j.text)\n",
    "    output = get_icd9_codes_groq(prompt_creation(input_))\n",
    "\n",
    "    processed_data = preprocess_icd9_codes(output, j.id)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyarrow polars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PUBMED RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PUBMED BASED RELEVANT ARTICLES ON MIMIC 3 test set \n",
    "sym_mim_3 = pd.read_csv('deep/symptoms_mimic3_related_articles.csv')\n",
    "sym_text_mim_3 = pd.read_csv('deep/text_with_symptoms_mimic3_related_articles.csv')\n",
    "\n",
    "## PUBMED BASED RELEVANT ARTICLES ON MIMIC 4 test set (Symptoms as query, and Symptoms + Note as query)\n",
    "sym_mim_4 = pd.read_csv('deep/symptoms_mimic4_related_articles.csv')\n",
    "sym_text_mim_4 = pd.read_csv('deep/text_with_symptoms_mimic4_related_articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>Diseases</th>\n",
       "      <th>id</th>\n",
       "      <th>icd_9_desc</th>\n",
       "      <th>text</th>\n",
       "      <th>long_texts</th>\n",
       "      <th>short_texts</th>\n",
       "      <th>discharge_summary</th>\n",
       "      <th>short_codes</th>\n",
       "      <th>num_codes</th>\n",
       "      <th>related_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8375</td>\n",
       "      <td>['bilateral upper extremity ecchymosses', 'hyp...</td>\n",
       "      <td>['cryptogenic cirrhosis', 'afib/SSS', 'fatty l...</td>\n",
       "      <td>155525</td>\n",
       "      <td>Unspecified septicemia,Septic shock,Pneumoniti...</td>\n",
       "      <td>CHIEF COMPLAINT: L. hand hematoma\\n\\nPRESENT I...</td>\n",
       "      <td>Unspecified septicemia,Septic shock,Pneumoniti...</td>\n",
       "      <td>Septicemia NOS,Septic shock,Food/vomit pneumon...</td>\n",
       "      <td>Admission Date:  [**2171-8-2**]              D...</td>\n",
       "      <td>038,785,507,518,584,348,511,456,572,285,428,27...</td>\n",
       "      <td>37</td>\n",
       "      <td>[{'id': '23327286', 'contents': \"Envenomation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3360</td>\n",
       "      <td>['altered mental status', 'GI bleed', 'hypoten...</td>\n",
       "      <td>['neurofibromatosis', 'HTN', 'hyperlipidemia',...</td>\n",
       "      <td>187452</td>\n",
       "      <td>Streptococcal septicemia,Septic shock,Acute re...</td>\n",
       "      <td>CHIEF COMPLAINT: altered mental status, GI ble...</td>\n",
       "      <td>Streptococcal septicemia,Septic shock,Acute re...</td>\n",
       "      <td>Streptococcal septicemia,Septic shock,Acute re...</td>\n",
       "      <td>Admission Date:  [**2172-9-8**]              D...</td>\n",
       "      <td>038,785,518,584,349,577,276,997,533,576,599,00...</td>\n",
       "      <td>35</td>\n",
       "      <td>[{'id': '22244603', 'contents': 'Hypermagnesem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>381</td>\n",
       "      <td>['abdominal pain', 'nonbloody emesis', 'hypote...</td>\n",
       "      <td>['Nonischemic dilated cardiomyopathy', 'hypert...</td>\n",
       "      <td>161002</td>\n",
       "      <td>Acute pancreatitis,Acute kidney failure with l...</td>\n",
       "      <td>CHIEF COMPLAINT: abdominal pain\\n\\nPRESENT ILL...</td>\n",
       "      <td>Acute pancreatitis,Acute kidney failure with l...</td>\n",
       "      <td>Acute pancreatitis,Ac kidny fail, tubr necr,Se...</td>\n",
       "      <td>Admission Date:  [**2135-4-4**]              D...</td>\n",
       "      <td>577,584,038,995,410,785,518,567,425,070,576,27...</td>\n",
       "      <td>34</td>\n",
       "      <td>[{'id': '24732098', 'contents': 'Collaborative...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7632</td>\n",
       "      <td>['bloody diarrhea', 'abdominal pain', 'intermi...</td>\n",
       "      <td>['mesenteric ischemia', 'bowel ischemia', 'atr...</td>\n",
       "      <td>119210</td>\n",
       "      <td>Infectious colitis, enteritis, and gastroenter...</td>\n",
       "      <td>CHIEF COMPLAINT: Mesenteric Ischemia\\n\\nPRESEN...</td>\n",
       "      <td>Infectious colitis, enteritis, and gastroenter...</td>\n",
       "      <td>Infectious enteritis NOS,Chr stomach ulc w hem...</td>\n",
       "      <td>Admission Date:  [**2136-2-9**]              D...</td>\n",
       "      <td>009,531,532,038,482,995,785,584,577,518,449,44...</td>\n",
       "      <td>34</td>\n",
       "      <td>[{'id': '2499181', 'contents': 'Histopathology...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6713</td>\n",
       "      <td>['abdominal pain', 'hypotension', 'decreased P...</td>\n",
       "      <td>['HTN', 'Type 2 DM', 'recent recurrent cholecy...</td>\n",
       "      <td>182497</td>\n",
       "      <td>Unspecified septicemia,Toxic encephalopathy,Ot...</td>\n",
       "      <td>CHIEF COMPLAINT: abdominal pain\\n\\nPRESENT ILL...</td>\n",
       "      <td>Unspecified septicemia,Toxic encephalopathy,Ot...</td>\n",
       "      <td>Septicemia NOS,Toxic encephalopathy,Ascites NE...</td>\n",
       "      <td>Admission Date:  [**2104-5-20**]              ...</td>\n",
       "      <td>038,349,789,276,599,286,511,575,041,995,783,57...</td>\n",
       "      <td>34</td>\n",
       "      <td>[{'id': '10714097', 'contents': 'Nonocclusive ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           Symptoms  \\\n",
       "0        8375  ['bilateral upper extremity ecchymosses', 'hyp...   \n",
       "1        3360  ['altered mental status', 'GI bleed', 'hypoten...   \n",
       "2         381  ['abdominal pain', 'nonbloody emesis', 'hypote...   \n",
       "3        7632  ['bloody diarrhea', 'abdominal pain', 'intermi...   \n",
       "4        6713  ['abdominal pain', 'hypotension', 'decreased P...   \n",
       "\n",
       "                                            Diseases      id  \\\n",
       "0  ['cryptogenic cirrhosis', 'afib/SSS', 'fatty l...  155525   \n",
       "1  ['neurofibromatosis', 'HTN', 'hyperlipidemia',...  187452   \n",
       "2  ['Nonischemic dilated cardiomyopathy', 'hypert...  161002   \n",
       "3  ['mesenteric ischemia', 'bowel ischemia', 'atr...  119210   \n",
       "4  ['HTN', 'Type 2 DM', 'recent recurrent cholecy...  182497   \n",
       "\n",
       "                                          icd_9_desc  \\\n",
       "0  Unspecified septicemia,Septic shock,Pneumoniti...   \n",
       "1  Streptococcal septicemia,Septic shock,Acute re...   \n",
       "2  Acute pancreatitis,Acute kidney failure with l...   \n",
       "3  Infectious colitis, enteritis, and gastroenter...   \n",
       "4  Unspecified septicemia,Toxic encephalopathy,Ot...   \n",
       "\n",
       "                                                text  \\\n",
       "0  CHIEF COMPLAINT: L. hand hematoma\\n\\nPRESENT I...   \n",
       "1  CHIEF COMPLAINT: altered mental status, GI ble...   \n",
       "2  CHIEF COMPLAINT: abdominal pain\\n\\nPRESENT ILL...   \n",
       "3  CHIEF COMPLAINT: Mesenteric Ischemia\\n\\nPRESEN...   \n",
       "4  CHIEF COMPLAINT: abdominal pain\\n\\nPRESENT ILL...   \n",
       "\n",
       "                                          long_texts  \\\n",
       "0  Unspecified septicemia,Septic shock,Pneumoniti...   \n",
       "1  Streptococcal septicemia,Septic shock,Acute re...   \n",
       "2  Acute pancreatitis,Acute kidney failure with l...   \n",
       "3  Infectious colitis, enteritis, and gastroenter...   \n",
       "4  Unspecified septicemia,Toxic encephalopathy,Ot...   \n",
       "\n",
       "                                         short_texts  \\\n",
       "0  Septicemia NOS,Septic shock,Food/vomit pneumon...   \n",
       "1  Streptococcal septicemia,Septic shock,Acute re...   \n",
       "2  Acute pancreatitis,Ac kidny fail, tubr necr,Se...   \n",
       "3  Infectious enteritis NOS,Chr stomach ulc w hem...   \n",
       "4  Septicemia NOS,Toxic encephalopathy,Ascites NE...   \n",
       "\n",
       "                                   discharge_summary  \\\n",
       "0  Admission Date:  [**2171-8-2**]              D...   \n",
       "1  Admission Date:  [**2172-9-8**]              D...   \n",
       "2  Admission Date:  [**2135-4-4**]              D...   \n",
       "3  Admission Date:  [**2136-2-9**]              D...   \n",
       "4  Admission Date:  [**2104-5-20**]              ...   \n",
       "\n",
       "                                         short_codes  num_codes  \\\n",
       "0  038,785,507,518,584,348,511,456,572,285,428,27...         37   \n",
       "1  038,785,518,584,349,577,276,997,533,576,599,00...         35   \n",
       "2  577,584,038,995,410,785,518,567,425,070,576,27...         34   \n",
       "3  009,531,532,038,482,995,785,584,577,518,449,44...         34   \n",
       "4  038,349,789,276,599,286,511,575,041,995,783,57...         34   \n",
       "\n",
       "                                    related_articles  \n",
       "0  [{'id': '23327286', 'contents': \"Envenomation ...  \n",
       "1  [{'id': '22244603', 'contents': 'Hypermagnesem...  \n",
       "2  [{'id': '24732098', 'contents': 'Collaborative...  \n",
       "3  [{'id': '2499181', 'contents': 'Histopathology...  \n",
       "4  [{'id': '10714097', 'contents': 'Nonocclusive ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym_mim_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIMIC 3 test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symptoms only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('infer_llm_pubmed_rag_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUBMED BASED RELEVANT ARTICLES ON MIMIC 3 test set \n",
    "\n",
    "for i, j in tqdm(sym_mim_3.iterrows(), total=len(sym_mim_3)):\n",
    "\n",
    "    symptom_list = ast.literal_eval(j[\"Symptoms\"])\n",
    "    true_label = j.short_codes.split(',')\n",
    "    true_length = len(true_label)\n",
    "    text = j.text\n",
    "    # kg_results = neo4j_handler.query_kg(symptom_list, 22)\n",
    "    #disease_codes = [i['disease'][:3] for i in kg_results]\n",
    "\n",
    "    results  = eval(j.related_articles)[:5]\n",
    "\n",
    "    input_ =   str(j.Symptoms)+ '\\n'  + str(j.text) \n",
    "    output = get_icd9_codes_mistral(prompt_creation_rag(input_, results))\n",
    "\n",
    "    processed_data = preprocess_icd9_codes(output, j.id, output_dir='infer_llm_pubmed_rag_5')\n",
    "\n",
    "    if i==200:\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test_df = pd.read_csv('symptoms_test.csv')\n",
    "raw_test_df = raw_test_df.drop('Unnamed: 0',axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159    250,518,428,789,599,276,V586,E932,427,584,403,...\n",
       "Name: short_codes, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym_mim_3[sym_mim_3.id == 140525].short_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(file_path, test_set = 'mimic_4', mimic_3_df= sym_mim_3) : \n",
    "\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "\n",
    "    for i in os.listdir(f'{file_path}'):\n",
    "        with open(f'{file_path}/{i}', 'r') as f:\n",
    "            note_id = i.split('icd9_codes_processed_')[1].split('.json')[0]\n",
    "        \n",
    "            data = json.loads(f.read())\n",
    "            pred_codes = list(set([i['code'] for i in data['icd9_codes']]))\n",
    "\n",
    "\n",
    "        # print(list(mimic_4_df[mimic_4_df.note_id == note_id].SHORT_CODES)[0])\n",
    "        if test_set == 'mimic_4' : \n",
    "            \n",
    "            true_codes = list(mimic_4_df[mimic_4_df.note_id == note_id].SHORT_CODES)[0].split(',')\n",
    "            \n",
    "        else : \n",
    " \n",
    "\n",
    "            \n",
    "            true_codes = list(mimic_3_df[mimic_3_df.id == int(note_id)].short_codes)[0].split(',')\n",
    "\n",
    "            \n",
    "\n",
    "        true_labels.append(true_codes)\n",
    "        pred_labels.append(pred_codes)\n",
    "    \n",
    "    print(len(true_labels), len(pred_labels))\n",
    "\n",
    "    f1_scores , prec, rec = [], [], []\n",
    "    for true_label,pred_label in zip(true_labels, pred_labels) : \n",
    "        precision, recall, f1 = calculate_f1(true_label, pred_label)\n",
    "        f1_scores.append(f1)\n",
    "        prec.append(precision)\n",
    "        rec.append(recall)\n",
    "\n",
    "    macro_f1_score = sum(f1_scores) / len(f1_scores)\n",
    "    macro_prec = sum(prec) / len(prec)\n",
    "    macro_rec = sum(rec) / len(rec)\n",
    "    print(f\"Macro Precision Score: {macro_prec:.4f}\")\n",
    "    print(f\"Macro Recall Score: {macro_rec:.4f}\")\n",
    "    print(f\"Macro F1 Score: {macro_f1_score:.4f}\")\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_predictions('infer_llm_pubmed_rag_5', test_set = 'mimic_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symptoms + Note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('infer_llm_pubmed_rag_5_mimic_3_sym_note')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MIMIC-3 test set : PUBMED RAG\n",
    "\n",
    "import gc\n",
    "\n",
    "def store_preds(test_df, type_ , top_n_docs, output_dir_, test_type ) : \n",
    "\n",
    "    for i, j in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "\n",
    "        symptom_list = ast.literal_eval(j[\"Symptoms\"])\n",
    "\n",
    "        if test_type == 'mimic_4' : \n",
    "            true_label = j.SHORT_CODES.split(',')\n",
    "        else : \n",
    "            true_label = j.short_codes.split(',')\n",
    "\n",
    "        true_length = len(true_label)\n",
    "        text = j.text\n",
    "\n",
    "        if type_  == 'kg': \n",
    "\n",
    "            kg_results = neo4j_handler.query_kg(symptom_list, 22)\n",
    "            disease_codes = [i['disease'][:3] for i in kg_results]\n",
    "            input_ =   str(j.Symptoms)+ '\\n'  + str(j.text) + '\\n' + str(disease_codes)\n",
    "        \n",
    "        else : \n",
    "            input_ =   str(j.Symptoms)+ '\\n'  + str(j.text)\n",
    "\n",
    "        results  = eval(j.related_articles)[:top_n_docs]\n",
    "\n",
    "        \n",
    "        output = get_icd9_codes_mistral(prompt_creation_rag(input_, results))\n",
    "\n",
    "        if test_type == 'mimic_4' : \n",
    "            processed_data = preprocess_icd9_codes(output, j.note_id, output_dir=output_dir_)\n",
    "        else : \n",
    "            processed_data = preprocess_icd9_codes(output, j.id, output_dir=output_dir_)\n",
    "\n",
    "        if i==100:\n",
    "            break\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_preds(sym_text_mim_3, 'non_kg' , top_n_docs=5, output_dir_= 'infer_llm_pubmed_rag_5_mimic_3_sym_note')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_predictions('infer_llm_pubmed_rag_5_mimic_3_sym_note', test_set = 'mimic_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now including kg as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mimic 3 symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('infer_llm_pubmed_rag_5_mimic_3_sym_kg_included')\n",
    "store_preds(sym_mim_3, 'kg' , top_n_docs=5, output_dir_= 'infer_llm_pubmed_rag_5_mimic_3_sym_kg_included')\n",
    "get_predictions('infer_llm_pubmed_rag_5_mimic_3_sym_kg_included', test_set = 'mimic_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mimic 3 symptoms + ehr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('infer_llm_pubmed_rag_5_mimic_3_sym_note_kg_included')\n",
    "store_preds(sym_text_mim_3, 'kg' , top_n_docs=5, output_dir_= 'infer_llm_pubmed_rag_5_mimic_3_sym_note_kg_included')\n",
    "get_predictions('infer_llm_pubmed_rag_5_mimic_3_sym_note_kg_included', test_set = 'mimic_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sym only + non-kg\n",
    "\n",
    "os.makedirs('infer_llm_pubmed_rag_10_mimic_3_sym')\n",
    "store_preds(sym_mim_3, 'non-kg' , top_n_docs=10, output_dir_= 'infer_llm_pubmed_rag_10_mimic_3_sym')\n",
    "get_predictions('infer_llm_pubmed_rag_10_mimic_3_sym', test_set = 'mimic_3')\n",
    "\n",
    "## sym+EHR  + non-kg\n",
    "\n",
    "os.makedirs('infer_llm_pubmed_rag_10_mimic_3_sym_note')\n",
    "store_preds(sym_text_mim_3, 'non-kg' , top_n_docs=10, output_dir_= 'infer_llm_pubmed_rag_10_mimic_3_sym_note')\n",
    "get_predictions('infer_llm_pubmed_rag_10_mimic_3_sym_note', test_set = 'mimic_3')\n",
    "\n",
    "## Sym only + kg\n",
    "\n",
    "os.makedirs('infer_llm_pubmed_rag_10_mimic_3_sym_kg_included')\n",
    "store_preds(sym_mim_3, 'kg' , top_n_docs=10, output_dir_= 'infer_llm_pubmed_rag_10_mimic_3_sym_kg_included')\n",
    "get_predictions('infer_llm_pubmed_rag_10_mimic_3_sym_kg_included', test_set = 'mimic_3')\n",
    "\n",
    "\n",
    "## Sym + EHR + kg\n",
    "\n",
    "os.makedirs('infer_llm_pubmed_rag_10_mimic_3_sym_note_kg_included')\n",
    "store_preds(sym_text_mim_3, 'kg' , top_n_docs=10, output_dir_= 'infer_llm_pubmed_rag_10_mimic_3_sym_note_kg_included')\n",
    "get_predictions('infer_llm_pubmed_rag_10_mimic_3_sym_note_kg_included', test_set = 'mimic_3')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mimic-4 test set on pubmed RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top n = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sym only + non-kg\n",
    "\n",
    "os.makedirs('infer_llm_pubmed_rag_5_mimic_4_sym',exist_ok=True)\n",
    "store_preds(sym_mim_4, 'non-kg' , top_n_docs=5, output_dir_= 'infer_llm_pubmed_rag_5_mimic_4_sym', test_type='mimic_4')\n",
    "get_predictions('infer_llm_pubmed_rag_5_mimic_4_sym', test_set = 'mimic_4')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sym+EHR  + non-kg\n",
    "\n",
    "os.makedirs('infer_llm_pubmed_rag_5_mimic_4_sym_note',exist_ok=True)\n",
    "store_preds(sym_text_mim_4, 'non-kg' , top_n_docs=5, output_dir_= 'infer_llm_pubmed_rag_5_mimic_4_sym_note', test_type='mimic_4')\n",
    "get_predictions('infer_llm_pubmed_rag_5_mimic_4_sym_note', test_set = 'mimic_4')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sym only + kg\n",
    "\n",
    "os.makedirs('infer_llm_pubmed_rag_5_mimic_4_sym_kg_included')\n",
    "store_preds(sym_mim_4, 'kg' , top_n_docs=5, output_dir_= 'infer_llm_pubmed_rag_5_mimic_4_sym_kg_included', test_type='mimic_4')\n",
    "get_predictions('infer_llm_pubmed_rag_5_mimic_4_sym_kg_included', test_set = 'mimic_4')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sym + EHR + kg\n",
    "\n",
    "os.makedirs('infer_llm_pubmed_rag_5_mimic_4_sym_note_kg_included',exist_ok=True)\n",
    "store_preds(sym_text_mim_4, 'kg' , top_n_docs=5, output_dir_= 'infer_llm_pubmed_rag_5_mimic_4_sym_note_kg_included', test_type='mimic_4')\n",
    "get_predictions('infer_llm_pubmed_rag_5_mimic_4_sym_note_kg_included', test_set = 'mimic_4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top n =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sym only + non-kg\n",
    "\n",
    "os.makedirs('infer_llm_pubmed_rag_10_mimic_4_sym',exist_ok=True)\n",
    "store_preds(sym_mim_4, 'non-kg' , top_n_docs=10, output_dir_= 'infer_llm_pubmed_rag_10_mimic_4_sym',  test_type='mimic_4')\n",
    "get_predictions('infer_llm_pubmed_rag_10_mimic_4_sym', test_set = 'mimic_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sym+EHR  + non-kg\n",
    "\n",
    "os.makedirs('infer_llm_pubmed_rag_10_mimic_4_sym_note')\n",
    "store_preds(sym_text_mim_4, 'non-kg' , top_n_docs=10, output_dir_= 'infer_llm_pubmed_rag_10_mimic_4_sym_note',  test_type='mimic_4')\n",
    "get_predictions('infer_llm_pubmed_rag_10_mimic_4_sym_note', test_set = 'mimic_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sym only + kg\n",
    "\n",
    "os.makedirs('infer_llm_pubmed_rag_10_mimic_4_sym_kg_included')\n",
    "store_preds(sym_mim_4, 'kg' , top_n_docs=10, output_dir_= 'infer_llm_pubmed_rag_10_mimic_4_sym_kg_included',  test_type='mimic_4')\n",
    "get_predictions('infer_llm_pubmed_rag_10_mimic_4_sym_kg_included', test_set = 'mimic_4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sym + EHR + kg\n",
    "\n",
    "os.makedirs('infer_llm_pubmed_rag_10_mimic_4_sym_note_kg_included')\n",
    "store_preds(sym_text_mim_4, 'kg' , top_n_docs=10, output_dir_= 'infer_llm_pubmed_rag_10_mimic_4_sym_note_kg_included',test_type='mimic_4' )\n",
    "get_predictions('infer_llm_pubmed_rag_10_mimic_4_sym_note_kg_included', test_set = 'mimic_4')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_results(approach = 'pubmed', model_only = True) : \n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    # Wrap raw_test_df.iterrows() with tqdm\n",
    "    output_file_path = \"llmwithKG.csv\"\n",
    "    with open(output_file_path, mode='w', newline='', encoding=\"utf-8\") as outfile:\n",
    "        fieldnames = [\"symptoms\", \"true_disease_codes\", \"predicted_diseases\", \"precision\", \"recall\", \"f1_score\"]\n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        # Generate predictions and calculate F1 scores\n",
    "        f1_scores = []\n",
    "        prec = []\n",
    "        rec = []\n",
    "        for i, j in tqdm(raw_test_df.iterrows(), total=len(raw_test_df)):\n",
    "            symptom_list = ast.literal_eval(j[\"Symptoms\"])\n",
    "            true_label = j.short_codes.split(',')\n",
    "            \n",
    "            if approach == 'pubmed' : \n",
    "\n",
    "                if model_only : \n",
    "\n",
    "                    pred_label = get_predictions_with_rag( str(j.Symptoms)+ '\\n' + str(j.text) , symptom_list, 22, 0.0643, model_only = True)\n",
    "                \n",
    "                else : \n",
    "\n",
    "                    pred_label = get_predictions_with_rag( str(j.Symptoms)+ '\\n' + str(j.text) , symptom_list,22, 0.0643, model_only = False)\n",
    "\n",
    "                # pred_label = get_predictions(str(j.text) + ' ' + str(j.Symptoms), 0.0643745388060965)\n",
    "                \n",
    "                true_labels.append(true_label)\n",
    "                predicted_labels.append(pred_label)\n",
    "\n",
    "                precision, recall, f1 = calculate_f1(true_label, pred_label)\n",
    "                f1_scores.append(f1)\n",
    "                prec.append(precision)\n",
    "                rec.append(recall)\n",
    "\n",
    "                \n",
    "                writer.writerow({\n",
    "                    \"symptoms\": str(j.Symptoms),\n",
    "                    \"true_disease_codes\": \", \".join(true_label),\n",
    "                    \"predicted_diseases\": \", \".join(map(str, pred_label)),\n",
    "                    \"precision\": precision,\n",
    "                    \"recall\": recall,\n",
    "                    \"f1_score\": f1\n",
    "                })\n",
    "            else : \n",
    "                try :     \n",
    "                    expanded_query = search_symptoms(j.Symptoms[2:-2].split(\"', '\"), limit = 5)\n",
    "\n",
    "                    \n",
    "                    # limit_ = len(true_label)\n",
    "                    pred_label = get_prioritized_relationships(expanded_query,weightage=1,limit = len(true_label))[0]\n",
    "                    \n",
    "                    \n",
    "                    input_text = str(j.text) + ' ' + str(j.Symptoms)\n",
    "                    augmented_input = f\"{input_text} \\n{kg_results}\"\n",
    "\n",
    "                    # Tokenize and predict using the model\n",
    "                    tokenized_input = tokenizer(\n",
    "                        augmented_input,\n",
    "                        return_tensors=\"pt\",\n",
    "                        truncation=True,\n",
    "                        max_length=512,\n",
    "                        padding='max_length'\n",
    "                    )\n",
    "                    tokenized_input = {k: v.to(device) for k, v in tokenized_input.items()}\n",
    "                    output = model(**tokenized_input)\n",
    "                    predictions = torch.sigmoid(output.logits)\n",
    "                    pred_label = [model.config.id2label[_id] for _id in (predictions > 0.0643).nonzero()[:, 1].tolist()][:len(true_label)]\n",
    "                    \n",
    "                  \n",
    "                    predicted_labels.append(pred_label)\n",
    "                    true_labels.append(list(set(true_label)))\n",
    "                    \n",
    "                    precision, recall, f1 = calculate_f1(true_label, pred_label)\n",
    "\n",
    "                    f1_scores.append(f1)\n",
    "                    prec.append(precision)\n",
    "                    rec.append(recall)\n",
    "\n",
    "                    writer.writerow({\n",
    "                    \"symptoms\": str(j.Symptoms),\n",
    "                    \"true_disease_codes\": \", \".join(true_label),\n",
    "                    \"predicted_diseases\": \", \".join(map(str, pred_label)),\n",
    "                    \"precision\": precision,\n",
    "                    \"recall\": recall,\n",
    "                    \"f1_score\": f1\n",
    "                })\n",
    "                    \n",
    "                except : \n",
    "                    print(j.Symptoms)\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            if i ==500: \n",
    "                break\n",
    "\n",
    "    return f1_scores, prec, rec, true_labels, predicted_labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores_model, prec, rec, true_labels, predicted_labels= get_results(approach= 'pubmed', model_only= True)\n",
    "\n",
    "\n",
    "macro_f1_score = sum(f1_scores_model) / len(f1_scores_model)\n",
    "macro_prec = sum(prec) / len(prec)\n",
    "macro_rec = sum(rec) / len(rec)\n",
    "print(f\"Macro Precision Score: {macro_prec:.4f}\")\n",
    "print(f\"Macro Recall Score: {macro_rec:.4f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1_score:.4f}\")\n",
    "# print(len(f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores_rag, prec, rec, true_labels, predicted_labels= get_results(approach= 'pubmed', model_only= False)\n",
    "\n",
    "\n",
    "macro_f1_score = sum(f1_scores_rag) / len(f1_scores_rag)\n",
    "macro_prec = sum(prec) / len(prec)\n",
    "macro_rec = sum(rec) / len(rec)\n",
    "print(f\"Macro Precision Score: {macro_prec:.4f}\")\n",
    "print(f\"Macro Recall Score: {macro_rec:.4f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1_score:.4f}\")\n",
    "# print(len(f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_files (name) : \n",
    "    pd.Series(f1_scores_rag).to_csv(f'f2_f1_scores_rag_{name}.csv', index = False)\n",
    "    pd.Series(f1_scores_model).to_csv(f'f2_f1_scores_model_{name}.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_files('betty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "def compare_methods(scores1, scores2, method1_name, method2_name, alpha=0.05):\n",
    "    t_stat, p_value = stats.ttest_rel(scores1, scores2)\n",
    "    \n",
    "    print(f\"Comparing {method1_name} vs {method2_name}\")\n",
    "    print(f\"t-statistic: {t_stat:.4f}\")\n",
    "    print(f\"p-value: {p_value:.4f}\")\n",
    "    \n",
    "    if p_value < alpha:\n",
    "        print(\"Statistically significant difference detected:\")\n",
    "        if t_stat > 0:\n",
    "            print(f\"{method1_name} performs significantly better\")\n",
    "        else:\n",
    "            print(f\"{method2_name} performs significantly better\")\n",
    "    else:\n",
    "        print(\"No statistically significant difference between methods\")\n",
    "\n",
    "compare_methods(f1_scores_model, f1_scores_rag, 'Model', 'Pubmed + KG', alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 101)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_labels), len(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "batch_size = 200 # Adjust based on memory limits\n",
    "\n",
    "metrics_list = []\n",
    "\n",
    "# Process batches directly from the labels, converting each batch to binary format on-the-fly\n",
    "for i in tqdm(range(0, len(true_labels), batch_size), desc=\"Processing Batches\"):\n",
    "    batch_true_labels = true_labels[i:i + batch_size]\n",
    "    batch_pred_labels = predicted_labels[i:i + batch_size]\n",
    "\n",
    "\n",
    "    # Create binary matrices for each batch\n",
    "    batch_true_matrix = create_binary_matrix(batch_true_labels, classes)\n",
    "    batch_pred_matrix = create_binary_matrix(batch_pred_labels, classes)\n",
    "\n",
    "    # Calculate metrics for the current batch\n",
    "    batch_metrics = roc_auc(batch_pred_matrix, batch_true_matrix, multilabel=True)\n",
    "    metrics_list.append(batch_metrics)\n",
    "\n",
    "\n",
    "# Average metrics across all batches\n",
    "final_metrics = {k: sum(d[k] for d in metrics_list) / len(metrics_list) for k in metrics_list[0]}\n",
    "print(final_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.7565715921239807"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores_dict = {\n",
    "    'rag_betty' :[],\n",
    "    'model_betty' :[],\n",
    "    'rag_biobert' : [],\n",
    "    'model_biobert' : [],\n",
    "    'rag_biolinkbert' :[],\n",
    "    'model_biolinkbert' : []\n",
    "}\n",
    "for i in f1_scores_dict.keys() : \n",
    "    f1_scores_dict[i] = pd.read_csv(f'f2_f1_scores_{i}.csv')['0'].to_list()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "\n",
    "def perform_t_tests(f1_scores):\n",
    "    \"\"\"\n",
    "    Perform pairwise t-tests between all approaches.\n",
    "    \n",
    "    Parameters:\n",
    "    f1_scores (dict): A dictionary with approach names as keys and F1 scores as values\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: T-test results for each pair of approaches\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Get all unique pairs of approaches\n",
    "    approach_pairs = list(combinations(f1_scores.keys(), 2))\n",
    "    \n",
    "    for approach1, approach2 in approach_pairs:\n",
    "        # Perform independent t-test\n",
    "        t_statistic, p_value = stats.ttest_ind(\n",
    "            f1_scores[approach1], \n",
    "            f1_scores[approach2]\n",
    "        )\n",
    "        \n",
    "        result = {\n",
    "            'Comparison': f'{approach1} vs {approach2}',\n",
    "\n",
    "            't-statistic': t_statistic,\n",
    "            # 'p-value': p_value,\n",
    "            'Significant (=0.05)': p_value < 0.05\n",
    "        }\n",
    "        results.append(result)\n",
    "    \n",
    "    # Create DataFrame and format numeric columns\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Format numeric columns\n",
    "    numeric_cols = [col for col in df.columns if col not in ['Comparison', 'Significant (=0.05)']]\n",
    "    for col in numeric_cols:\n",
    "        df[col] = df[col].map('{:.4f}'.format)\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Test Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comparison</th>\n",
       "      <th>t-statistic</th>\n",
       "      <th>Significant (=0.05)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rag_betty vs model_betty</td>\n",
       "      <td>6.7577</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rag_betty vs rag_biobert</td>\n",
       "      <td>2.5611</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rag_betty vs model_biobert</td>\n",
       "      <td>9.3267</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rag_betty vs rag_biolinkbert</td>\n",
       "      <td>-5.3433</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rag_betty vs model_biolinkbert</td>\n",
       "      <td>4.0756</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>model_betty vs rag_biobert</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>model_betty vs model_biobert</td>\n",
       "      <td>1.9568</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>model_betty vs rag_biolinkbert</td>\n",
       "      <td>-11.4790</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>model_betty vs model_biolinkbert</td>\n",
       "      <td>-2.4608</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rag_biobert vs model_biobert</td>\n",
       "      <td>6.8962</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rag_biobert vs rag_biolinkbert</td>\n",
       "      <td>-7.8456</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rag_biobert vs model_biolinkbert</td>\n",
       "      <td>1.7666</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>model_biobert vs rag_biolinkbert</td>\n",
       "      <td>-14.2200</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>model_biobert vs model_biolinkbert</td>\n",
       "      <td>-4.5442</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rag_biolinkbert vs model_biolinkbert</td>\n",
       "      <td>8.8617</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Comparison t-statistic  Significant (=0.05)\n",
       "0               rag_betty vs model_betty      6.7577                  True\n",
       "1               rag_betty vs rag_biobert      2.5611                  True\n",
       "2             rag_betty vs model_biobert      9.3267                  True\n",
       "3           rag_betty vs rag_biolinkbert     -5.3433                  True\n",
       "4         rag_betty vs model_biolinkbert      4.0756                  True\n",
       "5             model_betty vs rag_biobert     -4.4552                  True\n",
       "6           model_betty vs model_biobert      1.9568                 False\n",
       "7         model_betty vs rag_biolinkbert    -11.4790                  True\n",
       "8       model_betty vs model_biolinkbert     -2.4608                  True\n",
       "9           rag_biobert vs model_biobert      6.8962                  True\n",
       "10        rag_biobert vs rag_biolinkbert     -7.8456                  True\n",
       "11      rag_biobert vs model_biolinkbert      1.7666                 False\n",
       "12      model_biobert vs rag_biolinkbert    -14.2200                  True\n",
       "13    model_biobert vs model_biolinkbert     -4.5442                  True\n",
       "14  rag_biolinkbert vs model_biolinkbert      8.8617                  True"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Perform t-tests\n",
    "t_test_results = perform_t_tests(f1_scores_dict)\n",
    "\n",
    "# Print results\n",
    "print(\"T-Test Results:\")\n",
    "t_test_results\n",
    "\n",
    "# Optional: Save to CSV if needed\n",
    "# t_test_results.to_csv('f1_score_ttest_results.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weaviate_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
